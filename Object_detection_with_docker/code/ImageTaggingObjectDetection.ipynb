{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKydmAAOjusV"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442,
          "referenced_widgets": [
            "5b0f7d56e68c421f9e1154eb80eccf92",
            "0b79589a77934f989cb05be670255821",
            "ac05d72a255e49a6851f58b35c18731a",
            "ea824a0c571d48c59094e9b3c0d2b4cb",
            "da90b19b7bee455f8eac0adb3ed72e7e",
            "6bc838a0d54743ada3d355af46b87509",
            "3d47999e9ba6434f8ddcca0cc090d205",
            "7f405781a1c44f2298190be6eb73c073",
            "11177c3ef850464a80396b66d26c365a",
            "1bc2d13f93d74f9fac7422e3b9081470",
            "475234f867b64a7f96b8a0664673d394"
          ]
        },
        "id": "VRsCcxWfkrKA",
        "outputId": "9a9ba674-0898-475f-bf99-7e1427ed6b4d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b0f7d56e68c421f9e1154eb80eccf92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-1933593757.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dgural/bdd100k\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train[:1000]\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load a subset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m     \u001b[0;31m# Create a dataset builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2112\u001b[0;31m     builder_instance = load_dataset_builder(\n\u001b[0m\u001b[1;32m   2113\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1796\u001b[0m         \u001b[0mdownload_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdownload_config\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m     dataset_module = dataset_module_factory(\n\u001b[0m\u001b[1;32m   1799\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m                     \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m                     \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m                 ).get_module()\n\u001b[0m\u001b[1;32m   1480\u001b[0m         except (\n\u001b[1;32m   1481\u001b[0m             \u001b[0mException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mget_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0msanitize_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m             \u001b[0;32melse\u001b[0m \u001b[0mget_data_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m         )\n\u001b[1;32m   1036\u001b[0m         data_files = DataFilesDict.from_patterns(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mget_data_patterns\u001b[0;34m(base_path, download_config)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mresolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolve_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_data_files_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mEmptyDatasetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The directory at {base_path} doesn't contain any data files\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36m_get_data_files_patterns\u001b[0;34m(pattern_resolver)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{split}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mdata_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mresolve_pattern\u001b[0;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    338\u001b[0m     matched_paths = [\n\u001b[1;32m    339\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol_prefix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mprotocol_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles_to_ignore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_file_system.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"expand_info\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"detail\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"revision\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     def find(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/spec.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(self, path, maxdepth, **kwargs)\u001b[0m\n\u001b[1;32m    607\u001b[0m                 \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0mallpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwithdirs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mends_with_sep\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_file_system.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self, path, maxdepth, withdirs, detail, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \"\"\"\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxdepth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             return super().find(\n\u001b[0m\u001b[1;32m    557\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwithdirs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwithdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/spec.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self, path, maxdepth, withdirs, detail, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwithdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_file_system.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(self, path, *args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"expand_info\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"detail\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"revision\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/spec.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(self, path, maxdepth, topdown, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mdetail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"detail\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mlisting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mon_error\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_file_system.py\u001b[0m in \u001b[0;36mls\u001b[0;34m(self, path, detail, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"expand_info\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ls_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mEntryNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0;31m# Path could be a file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_file_system.py\u001b[0m in \u001b[0;36m_ls_tree\u001b[0;34m(self, path, recursive, refresh, revision, expand_info)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdircache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 out.extend(\n\u001b[0;32m--> 446\u001b[0;31m                     self._ls_tree(\n\u001b[0m\u001b[1;32m    447\u001b[0m                         \u001b[0mcommon_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                         \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_file_system.py\u001b[0m in \u001b[0;36m_ls_tree\u001b[0;34m(self, path, recursive, refresh, revision, expand_info)\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0mrepo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresolved_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepo_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             )\n\u001b[0;32m--> 463\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpath_info\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepoFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                     cache_path_info = {\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mlist_repo_tree\u001b[0;34m(self, repo_id, path_in_repo, recursive, expand, revision, repo_type, token)\u001b[0m\n\u001b[1;32m   3166\u001b[0m         \u001b[0mencoded_path_in_repo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_in_repo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpath_in_repo\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3167\u001b[0m         \u001b[0mtree_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{self.endpoint}/api/{repo_type}s/{repo_id}/tree/{revision}{encoded_path_in_repo}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3168\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpath_info\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaginate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtree_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"recursive\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"expand\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3169\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mRepoFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpath_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpath_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mRepoFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpath_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_pagination.py\u001b[0m in \u001b[0;36mpaginate\u001b[0;34m(path, params, headers)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mnext_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Pagination detected. Requesting next page: {next_page}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_page\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_on_status_codes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m429\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhttp_backoff\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;31m# Perform request and return if status_code is not in the retry list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mretry_on_status_codes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Send: {_curlify(request)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_AMZN_TRACE_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"dgural/bdd100k\", split=\"train[:1000]\")  # Load a subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YEDplQAwSgtO",
        "outputId": "2d3f7c85-b6fe-4d1e-e503-d5fa3d132b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.170-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.170-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m131.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.170 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mFy6991SbXU",
        "outputId": "f059c3c6-07cd-44c4-c2f7-c89db1f3292a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Fw2dDCKI3s0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tAgLcQpUTUBZ"
      },
      "outputs": [],
      "source": [
        "# CONFIGURATION\n",
        "video_dir = \"/content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train\"\n",
        "csv_path = \"/content/drive/MyDrive/driving-video-with-object-tracking/mot_labels.csv\" #This file contains object name, bounding box info per frame.\n",
        "output_dir = \"/content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_yolov11n\"\n",
        "\n",
        "# Directory setup\n",
        "img_train_dir = os.path.join(output_dir, \"images/train\")\n",
        "img_test_dir = os.path.join(output_dir, \"images/test\")\n",
        "label_train_dir = os.path.join(output_dir, \"labels/train\")\n",
        "label_test_dir = os.path.join(output_dir, \"labels/test\")\n",
        "\n",
        "os.makedirs(img_train_dir, exist_ok=True)\n",
        "os.makedirs(img_test_dir, exist_ok=True)\n",
        "os.makedirs(label_train_dir, exist_ok=True)\n",
        "os.makedirs(label_test_dir, exist_ok=True)\n",
        "\n",
        "image_width, image_height = 1280, 720  # Resolution of bdd100k videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QMPkNaahmpp",
        "outputId": "4b44f9b6-ac41-4625-a06e-365e023880dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Classes: ['bicycle', 'bus', 'car', 'motorcycle', 'other person', 'other vehicle', 'pedestrian', 'rider', 'trailer', 'train', 'truck']\n",
            "Class Map: {'bicycle': 0, 'bus': 1, 'car': 2, 'motorcycle': 3, 'other person': 4, 'other vehicle': 5, 'pedestrian': 6, 'rider': 7, 'trailer': 8, 'train': 9, 'truck': 10}\n"
          ]
        }
      ],
      "source": [
        "# Load CSV and extract unique classes\n",
        "df = pd.read_csv(csv_path, low_memory=False)\n",
        "unique_classes = sorted(df[\"category\"].dropna().unique().tolist())\n",
        "class_map = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
        "\n",
        "print(\"Unique Classes:\", unique_classes)\n",
        "print(\"Class Map:\", class_map)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_classes_idd = {'animal', 'autorickshaw', 'bicycle', 'bus', 'car', 'caravan', 'motorcycle', 'person', 'rider', 'traffic light', 'traffic sign', 'trailer', 'train', 'truck', 'vehicle fallback'}"
      ],
      "metadata": {
        "id": "UQDPl33-jMTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a classes set by merging unique_classes and unique_classes_idd\n",
        "class_map_combined = {\n",
        "    'bicycle': 0,\n",
        "    'bus': 1,\n",
        "    'car': 2,\n",
        "    'motorcycle': 3,\n",
        "    'other person': 4,\n",
        "    'other vehicle': 5,\n",
        "    'pedestrian': 6,\n",
        "    'rider': 7,\n",
        "    'trailer': 8,\n",
        "    'train': 9,\n",
        "    'truck': 10,\n",
        "    'animal': 11,\n",
        "    'autorickshaw': 12,\n",
        "    'caravan': 13,\n",
        "    'traffic light': 14,\n",
        "    'traffic sign': 15\n",
        "}"
      ],
      "metadata": {
        "id": "G9Da5p2ujfJg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pYQh1bwirM9",
        "outputId": "e685e4db-790c-4314-f085-6b35d23f6036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of unique classes 11\n",
            "category\n",
            "car              2207116\n",
            "pedestrian        381441\n",
            "truck             149823\n",
            "bus                57880\n",
            "bicycle            28477\n",
            "rider              20365\n",
            "other vehicle      19202\n",
            "motorcycle         12464\n",
            "other person        4453\n",
            "trailer             4103\n",
            "train               1592\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# print unique value and their respective counts for category column.\n",
        "print(\"Total number of unique classes\",len(unique_classes))\n",
        "print(df['category'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "ynt2MvV7LQhq",
        "outputId": "e96f4878-095f-4756-c9fd-1fdbef197871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            name          videoName  frameIndex       id  \\\n",
              "0  01c71072-718028b8-0000001.jpg  01c71072-718028b8           0  89537.0   \n",
              "1  01c71072-718028b8-0000001.jpg  01c71072-718028b8           0  89538.0   \n",
              "2  01c71072-718028b8-0000001.jpg  01c71072-718028b8           0  89539.0   \n",
              "3  01c71072-718028b8-0000001.jpg  01c71072-718028b8           0  89540.0   \n",
              "4  01c71072-718028b8-0000001.jpg  01c71072-718028b8           0  89541.0   \n",
              "\n",
              "     category attributes.crowd attributes.occluded attributes.truncated  \\\n",
              "0         car            False                True                False   \n",
              "1         car            False                True                False   \n",
              "2  pedestrian            False                True                False   \n",
              "3         car            False               False                False   \n",
              "4         car            False               False                False   \n",
              "\n",
              "     box2d.x1     box2d.x2    box2d.y1    box2d.y2  haveVideo  \n",
              "0  825.173210  1003.094688  355.011547  418.198614       True  \n",
              "1  484.295612   700.461894  346.697460  424.849885       True  \n",
              "2  645.588915   663.879908  338.383372  358.337182       True  \n",
              "3  120.969977   192.471132  359.168591  409.053118       True  \n",
              "4  251.501155   315.519630  354.180139  400.739030       True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a66f424-f600-441a-965f-a25de382a55b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>videoName</th>\n",
              "      <th>frameIndex</th>\n",
              "      <th>id</th>\n",
              "      <th>category</th>\n",
              "      <th>attributes.crowd</th>\n",
              "      <th>attributes.occluded</th>\n",
              "      <th>attributes.truncated</th>\n",
              "      <th>box2d.x1</th>\n",
              "      <th>box2d.x2</th>\n",
              "      <th>box2d.y1</th>\n",
              "      <th>box2d.y2</th>\n",
              "      <th>haveVideo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01c71072-718028b8-0000001.jpg</td>\n",
              "      <td>01c71072-718028b8</td>\n",
              "      <td>0</td>\n",
              "      <td>89537.0</td>\n",
              "      <td>car</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>825.173210</td>\n",
              "      <td>1003.094688</td>\n",
              "      <td>355.011547</td>\n",
              "      <td>418.198614</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01c71072-718028b8-0000001.jpg</td>\n",
              "      <td>01c71072-718028b8</td>\n",
              "      <td>0</td>\n",
              "      <td>89538.0</td>\n",
              "      <td>car</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>484.295612</td>\n",
              "      <td>700.461894</td>\n",
              "      <td>346.697460</td>\n",
              "      <td>424.849885</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01c71072-718028b8-0000001.jpg</td>\n",
              "      <td>01c71072-718028b8</td>\n",
              "      <td>0</td>\n",
              "      <td>89539.0</td>\n",
              "      <td>pedestrian</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>645.588915</td>\n",
              "      <td>663.879908</td>\n",
              "      <td>338.383372</td>\n",
              "      <td>358.337182</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01c71072-718028b8-0000001.jpg</td>\n",
              "      <td>01c71072-718028b8</td>\n",
              "      <td>0</td>\n",
              "      <td>89540.0</td>\n",
              "      <td>car</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>120.969977</td>\n",
              "      <td>192.471132</td>\n",
              "      <td>359.168591</td>\n",
              "      <td>409.053118</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01c71072-718028b8-0000001.jpg</td>\n",
              "      <td>01c71072-718028b8</td>\n",
              "      <td>0</td>\n",
              "      <td>89541.0</td>\n",
              "      <td>car</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>251.501155</td>\n",
              "      <td>315.519630</td>\n",
              "      <td>354.180139</td>\n",
              "      <td>400.739030</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a66f424-f600-441a-965f-a25de382a55b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a66f424-f600-441a-965f-a25de382a55b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a66f424-f600-441a-965f-a25de382a55b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-04086894-a2de-493b-b21a-7882f67c8c72\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-04086894-a2de-493b-b21a-7882f67c8c72')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-04086894-a2de-493b-b21a-7882f67c8c72 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxvIInWGlHDU",
        "outputId": "37ca248e-6ee8-48ac-c885-7a6f1cb8b918"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        }
      ],
      "source": [
        "print(len(os.listdir(video_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_names = df[\"videoName\"].unique()\n",
        "print(\"Total number of unique video names\",len(video_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8touaUQ94E-6",
        "outputId": "5f93b639-bf48-4948-a7b0-375422219ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of unique video names 1400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video = \"0000f77c-6257be58.mov\"\n",
        "\n",
        "if video in set(os.listdir(video_dir)):\n",
        "    print(f\"Video '{video}' exists in the Train videos.\")\n",
        "else:\n",
        "    print(f\"Video '{video}' does not exist in the Train videos.\")\n",
        "label = \"0000f77c-6257be58\"\n",
        "if label in video_names:\n",
        "    print(f\"Video '{label}' exists in the DataFrame.\")\n",
        "else:\n",
        "    print(f\"Video '{label}' does not exist in the DataFrame.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSCP1K_pSrpQ",
        "outputId": "c74672bc-7598-4094-f549-8ce719642c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video '0000f77c-6257be58.mov' exists in the Train videos.\n",
            "Video '0000f77c-6257be58' exists in the DataFrame.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract_frames(video, )"
      ],
      "metadata": {
        "id": "1PO2SrydX7j6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split by videoName\n",
        "video_names = df[\"videoName\"].unique()\n",
        "train_videos, test_videos = train_test_split(video_names, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "0lOGQgdDDQZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_videos_subset = train_videos[:2]\n",
        "test_videos_subset = test_videos[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "1MHf7t_Y1hDv",
        "outputId": "8173cbb7-594d-49cc-e05e-3e4f48e9493b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_videos' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-9-4013197728.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_videos_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_videos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_videos_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_videos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_videos' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"number of train videos: {len(train_videos_subset)}\")\n",
        "print(f\"number of test videos: {len(test_videos_subset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESAtvr1lFiyH",
        "outputId": "96a40c95-2d93-4cac-da57-46a992fd65d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of train videos: 2\n",
            "number of test videos: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"number of train videos: {len(train_videos)}\")\n",
        "print(f\"number of test videos: {len(test_videos)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgf5LLmIb1a6",
        "outputId": "0c5a36cf-06e5-4bf6-8ee8-fb00b28913d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of train videos: 1260\n",
            "number of test videos: 140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_frames(video_files, img_dir):\n",
        "  num_videos = len(video_files)\n",
        "  i = 0\n",
        "  for video_file in video_files:\n",
        "\n",
        "    vid_path = os.path.join(video_dir, video_file )\n",
        "    vid_name = os.path.splitext(video_file)[0]\n",
        "    print(f\"🎬 Processing video {i + 1}/{num_videos}: {video_file}\")\n",
        "    print(f\"vid_path: {vid_path}\")\n",
        "\n",
        "    cap = cv2.VideoCapture(vid_path)\n",
        "    frame_id = 0\n",
        "    saved_frame_count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        # Save only every 6th frame\n",
        "        if (frame_id+1) % 6 == 0 or frame_id == 0:\n",
        "            fname = f\"{vid_name}_frame_{saved_frame_count:05d}.jpg\"\n",
        "            #rotated_img = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
        "            cv2.imwrite(os.path.join(img_dir, fname), frame)\n",
        "            saved_frame_count += 1\n",
        "            print(f\"\\r🎬 Processing video {i + 1}/{num_videos}: {video_file} - Saved Frame {frame_id:05d}\", end=\"\")\n",
        "        frame_id += 1\n",
        "\n",
        "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    print(f\"\\r🎬 Finished video {i + 1}/{num_videos}: {video_file} - Total frames processed: {num_frames}, Frames saved: {saved_frame_count}\")\n",
        "\n",
        "    cap.release()\n",
        "    i+=1"
      ],
      "metadata": {
        "id": "mFyMdixfcKjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_files = sorted([f for f in os.listdir(video_dir) if f.lower().endswith(\".mov\")])\n",
        "num_videos = len(video_files)\n",
        "print(f\"\\n🎞️ Found {num_videos} .mov files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMNMjAMKsGeI",
        "outputId": "bcbc1a4d-cb8b-4687-f19f-a4c7e0d8b255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎞️ Found 1000 .mov files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract_frames(video_files[:200], img_train_dir)\n",
        "extract_frames(video_files[200:300], img_test_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M8hcw1MS1zqs",
        "outputId": "e87ea086-0117-4a50-d87f-d62fdf42b36d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎬 Processing video 1/200: 0000f77c-6257be58.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0000f77c-6257be58.mov\n",
            "🎬 Finished video 1/200: 0000f77c-6257be58.mov - Total frames processed: 1217, Frames saved: 203\n",
            "🎬 Processing video 2/200: 0000f77c-62c2a288.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0000f77c-62c2a288.mov\n",
            "🎬 Finished video 2/200: 0000f77c-62c2a288.mov - Total frames processed: 1211, Frames saved: 202\n",
            "🎬 Processing video 3/200: 0000f77c-cb820c98.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0000f77c-cb820c98.mov\n",
            "🎬 Finished video 3/200: 0000f77c-cb820c98.mov - Total frames processed: 1215, Frames saved: 203\n",
            "🎬 Processing video 4/200: 0001542f-5ce3cf52.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0001542f-5ce3cf52.mov\n",
            "🎬 Finished video 4/200: 0001542f-5ce3cf52.mov - Total frames processed: 1213, Frames saved: 203\n",
            "🎬 Processing video 5/200: 0001542f-7c670be8.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0001542f-7c670be8.mov\n",
            "🎬 Finished video 5/200: 0001542f-7c670be8.mov - Total frames processed: 1215, Frames saved: 203\n",
            "🎬 Processing video 6/200: 0001542f-ec815219.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0001542f-ec815219.mov\n",
            "🎬 Finished video 6/200: 0001542f-ec815219.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 7/200: 0004974f-05e1c285.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0004974f-05e1c285.mov\n",
            "🎬 Finished video 7/200: 0004974f-05e1c285.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 8/200: 00054602-3bf57337.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00054602-3bf57337.mov\n",
            "🎬 Finished video 8/200: 00054602-3bf57337.mov - Total frames processed: 1223, Frames saved: 204\n",
            "🎬 Processing video 9/200: 00067cfb-5443fe39.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00067cfb-5443fe39.mov\n",
            "🎬 Finished video 9/200: 00067cfb-5443fe39.mov - Total frames processed: 1202, Frames saved: 201\n",
            "🎬 Processing video 10/200: 00067cfb-5adfaaa7.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00067cfb-5adfaaa7.mov\n",
            "🎬 Finished video 10/200: 00067cfb-5adfaaa7.mov - Total frames processed: 1214, Frames saved: 203\n",
            "🎬 Processing video 11/200: 00067cfb-caba8a02.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00067cfb-caba8a02.mov\n",
            "🎬 Finished video 11/200: 00067cfb-caba8a02.mov - Total frames processed: 1206, Frames saved: 202\n",
            "🎬 Processing video 12/200: 00067cfb-e535423e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00067cfb-e535423e.mov\n",
            "🎬 Finished video 12/200: 00067cfb-e535423e.mov - Total frames processed: 1206, Frames saved: 202\n",
            "🎬 Processing video 13/200: 00067cfb-f1b91e3c.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00067cfb-f1b91e3c.mov\n",
            "🎬 Finished video 13/200: 00067cfb-f1b91e3c.mov - Total frames processed: 1201, Frames saved: 201\n",
            "🎬 Processing video 14/200: 0008a165-c48f4b3e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0008a165-c48f4b3e.mov\n",
            "🎬 Finished video 14/200: 0008a165-c48f4b3e.mov - Total frames processed: 1202, Frames saved: 201\n",
            "🎬 Processing video 15/200: 00091078-59817bb0.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00091078-59817bb0.mov\n",
            "🎬 Finished video 15/200: 00091078-59817bb0.mov - Total frames processed: 1204, Frames saved: 201\n",
            "🎬 Processing video 16/200: 00091078-7cff8ea6.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00091078-7cff8ea6.mov\n",
            "🎬 Finished video 16/200: 00091078-7cff8ea6.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 17/200: 00091078-84635cf2.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00091078-84635cf2.mov\n",
            "🎬 Finished video 17/200: 00091078-84635cf2.mov - Total frames processed: 606, Frames saved: 102\n",
            "🎬 Processing video 18/200: 00091078-875c1f73.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00091078-875c1f73.mov\n",
            "🎬 Finished video 18/200: 00091078-875c1f73.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 19/200: 00091078-c1d32eea.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00091078-c1d32eea.mov\n",
            "🎬 Finished video 19/200: 00091078-c1d32eea.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 20/200: 00091078-cedbfea7.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00091078-cedbfea7.mov\n",
            "🎬 Finished video 20/200: 00091078-cedbfea7.mov - Total frames processed: 1567, Frames saved: 262\n",
            "🎬 Processing video 21/200: 00091078-f32de4d2.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00091078-f32de4d2.mov\n",
            "🎬 Finished video 21/200: 00091078-f32de4d2.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 22/200: 000d35d3-41990aa4.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/000d35d3-41990aa4.mov\n",
            "🎬 Finished video 22/200: 000d35d3-41990aa4.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 23/200: 000d4f89-3bcbe37a.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/000d4f89-3bcbe37a.mov\n",
            "🎬 Finished video 23/200: 000d4f89-3bcbe37a.mov - Total frames processed: 1198, Frames saved: 200\n",
            "🎬 Processing video 24/200: 000e0252-8523a4a9.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/000e0252-8523a4a9.mov\n",
            "🎬 Finished video 24/200: 000e0252-8523a4a9.mov - Total frames processed: 1204, Frames saved: 201\n",
            "🎬 Processing video 25/200: 000f157f-30b30f5e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/000f157f-30b30f5e.mov\n",
            "🎬 Finished video 25/200: 000f157f-30b30f5e.mov - Total frames processed: 1216, Frames saved: 203\n",
            "🎬 Processing video 26/200: 000f157f-37797ff9.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/000f157f-37797ff9.mov\n",
            "🎬 Finished video 26/200: 000f157f-37797ff9.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 27/200: 000f157f-dab3a407.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/000f157f-dab3a407.mov\n",
            "🎬 Finished video 27/200: 000f157f-dab3a407.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 28/200: 000f8d37-d4c09a0f.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/000f8d37-d4c09a0f.mov\n",
            "🎬 Finished video 28/200: 000f8d37-d4c09a0f.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 29/200: 0010bf16-9ee17cd9.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0010bf16-9ee17cd9.mov\n",
            "🎬 Finished video 29/200: 0010bf16-9ee17cd9.mov - Total frames processed: 1192, Frames saved: 199\n",
            "🎬 Processing video 30/200: 0010bf16-a457685b.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0010bf16-a457685b.mov\n",
            "🎬 Finished video 30/200: 0010bf16-a457685b.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 31/200: 00131ea7-624f538d.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00131ea7-624f538d.mov\n",
            "🎬 Finished video 31/200: 00131ea7-624f538d.mov - Total frames processed: 1214, Frames saved: 203\n",
            "🎬 Processing video 32/200: 00134776-9123d227.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00134776-9123d227.mov\n",
            "🎬 Finished video 32/200: 00134776-9123d227.mov - Total frames processed: 1204, Frames saved: 201\n",
            "🎬 Processing video 33/200: 001bad4e-2fa8f3b6.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/001bad4e-2fa8f3b6.mov\n",
            "🎬 Finished video 33/200: 001bad4e-2fa8f3b6.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 34/200: 001c5339-08faca55.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/001c5339-08faca55.mov\n",
            "🎬 Finished video 34/200: 001c5339-08faca55.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 35/200: 001c5339-13a07470.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/001c5339-13a07470.mov\n",
            "🎬 Finished video 35/200: 001c5339-13a07470.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 36/200: 001c5339-9a6cdd3e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/001c5339-9a6cdd3e.mov\n",
            "🎬 Finished video 36/200: 001c5339-9a6cdd3e.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 37/200: 00202076-7a95b4e3.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00202076-7a95b4e3.mov\n",
            "🎬 Finished video 37/200: 00202076-7a95b4e3.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 38/200: 00202076-9eaa8e42.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00202076-9eaa8e42.mov\n",
            "🎬 Finished video 38/200: 00202076-9eaa8e42.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 39/200: 00207869-046fa443.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00207869-046fa443.mov\n",
            "🎬 Finished video 39/200: 00207869-046fa443.mov - Total frames processed: 1212, Frames saved: 203\n",
            "🎬 Processing video 40/200: 00207869-902288d1.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00207869-902288d1.mov\n",
            "🎬 Finished video 40/200: 00207869-902288d1.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 41/200: 00211b17-ad3e206b.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00211b17-ad3e206b.mov\n",
            "🎬 Finished video 41/200: 00211b17-ad3e206b.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 42/200: 00225f53-4200bde2.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00225f53-4200bde2.mov\n",
            "🎬 Finished video 42/200: 00225f53-4200bde2.mov - Total frames processed: 1212, Frames saved: 203\n",
            "🎬 Processing video 43/200: 00225f53-67614580.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00225f53-67614580.mov\n",
            "🎬 Finished video 43/200: 00225f53-67614580.mov - Total frames processed: 1206, Frames saved: 202\n",
            "🎬 Processing video 44/200: 00232de3-19eca24a.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00232de3-19eca24a.mov\n",
            "🎬 Finished video 44/200: 00232de3-19eca24a.mov - Total frames processed: 1204, Frames saved: 201\n",
            "🎬 Processing video 45/200: 0024b742-83709bd4.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0024b742-83709bd4.mov\n",
            "🎬 Finished video 45/200: 0024b742-83709bd4.mov - Total frames processed: 1197, Frames saved: 200\n",
            "🎬 Processing video 46/200: 0024b742-acbed4fb.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0024b742-acbed4fb.mov\n",
            "🎬 Finished video 46/200: 0024b742-acbed4fb.mov - Total frames processed: 614, Frames saved: 103\n",
            "🎬 Processing video 47/200: 002685b6-856c17f7.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/002685b6-856c17f7.mov\n",
            "🎬 Finished video 47/200: 002685b6-856c17f7.mov - Total frames processed: 1212, Frames saved: 203\n",
            "🎬 Processing video 48/200: 00268999-0b20ef00.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00268999-0b20ef00.mov\n",
            "🎬 Finished video 48/200: 00268999-0b20ef00.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 49/200: 00268999-9f6d5823.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00268999-9f6d5823.mov\n",
            "🎬 Finished video 49/200: 00268999-9f6d5823.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 50/200: 00268999-a4b8e39d.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00268999-a4b8e39d.mov\n",
            "🎬 Finished video 50/200: 00268999-a4b8e39d.mov - Total frames processed: 1198, Frames saved: 200\n",
            "🎬 Processing video 51/200: 00268999-cb063914.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00268999-cb063914.mov\n",
            "🎬 Finished video 51/200: 00268999-cb063914.mov - Total frames processed: 1194, Frames saved: 200\n",
            "🎬 Processing video 52/200: 002827ad-8748e2fb.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/002827ad-8748e2fb.mov\n",
            "🎬 Finished video 52/200: 002827ad-8748e2fb.mov - Total frames processed: 1214, Frames saved: 203\n",
            "🎬 Processing video 53/200: 0028cbbf-92f30408.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0028cbbf-92f30408.mov\n",
            "🎬 Finished video 53/200: 0028cbbf-92f30408.mov - Total frames processed: 1211, Frames saved: 202\n",
            "🎬 Processing video 54/200: 002ab96a-a96704f9.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/002ab96a-a96704f9.mov\n",
            "🎬 Finished video 54/200: 002ab96a-a96704f9.mov - Total frames processed: 1214, Frames saved: 203\n",
            "🎬 Processing video 55/200: 002ab96a-ea678692.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/002ab96a-ea678692.mov\n",
            "🎬 Finished video 55/200: 002ab96a-ea678692.mov - Total frames processed: 1204, Frames saved: 201\n",
            "🎬 Processing video 56/200: 002b485a-3f6603f2.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/002b485a-3f6603f2.mov\n",
            "🎬 Finished video 56/200: 002b485a-3f6603f2.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 57/200: 002b485a-d1301c7c.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/002b485a-d1301c7c.mov\n",
            "🎬 Finished video 57/200: 002b485a-d1301c7c.mov - Total frames processed: 1206, Frames saved: 202\n",
            "🎬 Processing video 58/200: 002b562f-e0ac84fe.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/002b562f-e0ac84fe.mov\n",
            "🎬 Finished video 58/200: 002b562f-e0ac84fe.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 59/200: 002cd38e-c7defded.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/002cd38e-c7defded.mov\n",
            "🎬 Finished video 59/200: 002cd38e-c7defded.mov - Total frames processed: 1204, Frames saved: 201\n",
            "🎬 Processing video 60/200: 002cd38e-ebe888e1.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/002cd38e-ebe888e1.mov\n",
            "🎬 Finished video 60/200: 002cd38e-ebe888e1.mov - Total frames processed: 1204, Frames saved: 201\n",
            "🎬 Processing video 61/200: 002d290d-01969e7d.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/002d290d-01969e7d.mov\n",
            "🎬 Finished video 61/200: 002d290d-01969e7d.mov - Total frames processed: 1204, Frames saved: 201\n",
            "🎬 Processing video 62/200: 002d290d-89d1aea8.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/002d290d-89d1aea8.mov\n",
            "🎬 Finished video 62/200: 002d290d-89d1aea8.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 63/200: 002d290d-89f4e5c0.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/002d290d-89f4e5c0.mov\n",
            "🎬 Finished video 63/200: 002d290d-89f4e5c0.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 64/200: 002d290d-90f2bab2.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/002d290d-90f2bab2.mov\n",
            "🎬 Finished video 64/200: 002d290d-90f2bab2.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 65/200: 002d290d-f9108a13.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/002d290d-f9108a13.mov\n",
            "🎬 Finished video 65/200: 002d290d-f9108a13.mov - Total frames processed: 1212, Frames saved: 203\n",
            "🎬 Processing video 66/200: 002d290d-fa2a8964.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/002d290d-fa2a8964.mov\n",
            "🎬 Finished video 66/200: 002d290d-fa2a8964.mov - Total frames processed: 1206, Frames saved: 202\n",
            "🎬 Processing video 67/200: 002e6895-442e6bc1.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/002e6895-442e6bc1.mov\n",
            "🎬 Finished video 67/200: 002e6895-442e6bc1.mov - Total frames processed: 1199, Frames saved: 200\n",
            "🎬 Processing video 68/200: 002f8552-0cdd55c6.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/002f8552-0cdd55c6.mov\n",
            "🎬 Finished video 68/200: 002f8552-0cdd55c6.mov - Total frames processed: 603, Frames saved: 101\n",
            "🎬 Processing video 69/200: 0030f434-3eb4a3a9.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0030f434-3eb4a3a9.mov\n",
            "🎬 Finished video 69/200: 0030f434-3eb4a3a9.mov - Total frames processed: 1214, Frames saved: 203\n",
            "🎬 Processing video 70/200: 00313a01-62156032.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00313a01-62156032.mov\n",
            "🎬 Finished video 70/200: 00313a01-62156032.mov - Total frames processed: 1206, Frames saved: 202\n",
            "🎬 Processing video 71/200: 00313a01-725ddf3a.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00313a01-725ddf3a.mov\n",
            "🎬 Finished video 71/200: 00313a01-725ddf3a.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 72/200: 00313a01-97de1f42.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00313a01-97de1f42.mov\n",
            "🎬 Finished video 72/200: 00313a01-97de1f42.mov - Total frames processed: 1211, Frames saved: 202\n",
            "🎬 Processing video 73/200: 00313a01-b53a2998.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00313a01-b53a2998.mov\n",
            "🎬 Finished video 73/200: 00313a01-b53a2998.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 74/200: 00322f82-286ab9b3.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00322f82-286ab9b3.mov\n",
            "🎬 Finished video 74/200: 00322f82-286ab9b3.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 75/200: 0032419c-7d20b300.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0032419c-7d20b300.mov\n",
            "🎬 Finished video 75/200: 0032419c-7d20b300.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 76/200: 0033b19f-65613f7e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0033b19f-65613f7e.mov\n",
            "🎬 Finished video 76/200: 0033b19f-65613f7e.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 77/200: 0033b19f-7f07efac.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0033b19f-7f07efac.mov\n",
            "🎬 Finished video 77/200: 0033b19f-7f07efac.mov - Total frames processed: 1215, Frames saved: 203\n",
            "🎬 Processing video 78/200: 0034a363-24f318c4.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0034a363-24f318c4.mov\n",
            "🎬 Finished video 78/200: 0034a363-24f318c4.mov - Total frames processed: 1214, Frames saved: 203\n",
            "🎬 Processing video 79/200: 0035afff-3295dbd6.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0035afff-3295dbd6.mov\n",
            "🎬 Finished video 79/200: 0035afff-3295dbd6.mov - Total frames processed: 1211, Frames saved: 202\n",
            "🎬 Processing video 80/200: 0035afff-434368a1.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0035afff-434368a1.mov\n",
            "🎬 Finished video 80/200: 0035afff-434368a1.mov - Total frames processed: 1206, Frames saved: 202\n",
            "🎬 Processing video 81/200: 0035afff-47378fa3.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0035afff-47378fa3.mov\n",
            "🎬 Finished video 81/200: 0035afff-47378fa3.mov - Total frames processed: 1204, Frames saved: 201\n",
            "🎬 Processing video 82/200: 0035afff-572b2d4e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0035afff-572b2d4e.mov\n",
            "🎬 Finished video 82/200: 0035afff-572b2d4e.mov - Total frames processed: 1206, Frames saved: 202\n",
            "🎬 Processing video 83/200: 0035afff-bd191d6a.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0035afff-bd191d6a.mov\n",
            "🎬 Finished video 83/200: 0035afff-bd191d6a.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 84/200: 00378858-c5f802ac.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00378858-c5f802ac.mov\n",
            "🎬 Finished video 84/200: 00378858-c5f802ac.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 85/200: 00390995-49d9a01e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00390995-49d9a01e.mov\n",
            "🎬 Finished video 85/200: 00390995-49d9a01e.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 86/200: 00391a82-8be5b76d.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00391a82-8be5b76d.mov\n",
            "🎬 Finished video 86/200: 00391a82-8be5b76d.mov - Total frames processed: 1211, Frames saved: 202\n",
            "🎬 Processing video 87/200: 00391a82-d1428e56.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00391a82-d1428e56.mov\n",
            "🎬 Finished video 87/200: 00391a82-d1428e56.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 88/200: 003baca5-70c87fc6.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/003baca5-70c87fc6.mov\n",
            "🎬 Finished video 88/200: 003baca5-70c87fc6.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 89/200: 003baca5-aab2e274.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/003baca5-aab2e274.mov\n",
            "🎬 Finished video 89/200: 003baca5-aab2e274.mov - Total frames processed: 1201, Frames saved: 201\n",
            "🎬 Processing video 90/200: 003baca5-ad660439.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/003baca5-ad660439.mov\n",
            "🎬 Finished video 90/200: 003baca5-ad660439.mov - Total frames processed: 1206, Frames saved: 202\n",
            "🎬 Processing video 91/200: 003baca5-d6cd84e5.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/003baca5-d6cd84e5.mov\n",
            "🎬 Finished video 91/200: 003baca5-d6cd84e5.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 92/200: 003c4a61-52588960.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/003c4a61-52588960.mov\n",
            "🎬 Finished video 92/200: 003c4a61-52588960.mov - Total frames processed: 1211, Frames saved: 202\n",
            "🎬 Processing video 93/200: 003e23ee-07d32feb.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/003e23ee-07d32feb.mov\n",
            "🎬 Finished video 93/200: 003e23ee-07d32feb.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 94/200: 003e23ee-67d25f19.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/003e23ee-67d25f19.mov\n",
            "🎬 Finished video 94/200: 003e23ee-67d25f19.mov - Total frames processed: 1201, Frames saved: 201\n",
            "🎬 Processing video 95/200: 004071a4-049b7b85.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/004071a4-049b7b85.mov\n",
            "🎬 Finished video 95/200: 004071a4-049b7b85.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 96/200: 004071a4-4e8a363a.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/004071a4-4e8a363a.mov\n",
            "🎬 Finished video 96/200: 004071a4-4e8a363a.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 97/200: 004071a4-a45d905f.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/004071a4-a45d905f.mov\n",
            "🎬 Finished video 97/200: 004071a4-a45d905f.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 98/200: 004071a4-ef4bf541.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/004071a4-ef4bf541.mov\n",
            "🎬 Finished video 98/200: 004071a4-ef4bf541.mov - Total frames processed: 1212, Frames saved: 203\n",
            "🎬 Processing video 99/200: 00417c23-220bbc98.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00417c23-220bbc98.mov\n",
            "🎬 Finished video 99/200: 00417c23-220bbc98.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 100/200: 00423717-0ef3c8dc.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00423717-0ef3c8dc.mov\n",
            "🎬 Finished video 100/200: 00423717-0ef3c8dc.mov - Total frames processed: 1200, Frames saved: 201\n",
            "🎬 Processing video 101/200: 00423717-eba4da41.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00423717-eba4da41.mov\n",
            "🎬 Finished video 101/200: 00423717-eba4da41.mov - Total frames processed: 1206, Frames saved: 202\n",
            "🎬 Processing video 102/200: 00423ac5-1fa7ff43.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00423ac5-1fa7ff43.mov\n",
            "🎬 Finished video 102/200: 00423ac5-1fa7ff43.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 103/200: 0045e757-02530231.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0045e757-02530231.mov\n",
            "🎬 Finished video 103/200: 0045e757-02530231.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 104/200: 0045e757-088840fc.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0045e757-088840fc.mov\n",
            "🎬 Finished video 104/200: 0045e757-088840fc.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 105/200: 0045e757-66a334b5.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0045e757-66a334b5.mov\n",
            "🎬 Finished video 105/200: 0045e757-66a334b5.mov - Total frames processed: 1202, Frames saved: 201\n",
            "🎬 Processing video 106/200: 004855fc-ff3946ad.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/004855fc-ff3946ad.mov\n",
            "🎬 Finished video 106/200: 004855fc-ff3946ad.mov - Total frames processed: 1201, Frames saved: 201\n",
            "🎬 Processing video 107/200: 00488a66-6c729bde.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00488a66-6c729bde.mov\n",
            "🎬 Finished video 107/200: 00488a66-6c729bde.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 108/200: 00488b40-0a8cf1a0.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00488b40-0a8cf1a0.mov\n",
            "🎬 Finished video 108/200: 00488b40-0a8cf1a0.mov - Total frames processed: 1216, Frames saved: 203\n",
            "🎬 Processing video 109/200: 0048f391-2c5344eb.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0048f391-2c5344eb.mov\n",
            "🎬 Finished video 109/200: 0048f391-2c5344eb.mov - Total frames processed: 1201, Frames saved: 201\n",
            "🎬 Processing video 110/200: 0048f391-8eb40ca6.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0048f391-8eb40ca6.mov\n",
            "🎬 Finished video 110/200: 0048f391-8eb40ca6.mov - Total frames processed: 1219, Frames saved: 204\n",
            "🎬 Processing video 111/200: 0048f391-e9bfaf62.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0048f391-e9bfaf62.mov\n",
            "🎬 Finished video 111/200: 0048f391-e9bfaf62.mov - Total frames processed: 1213, Frames saved: 203\n",
            "🎬 Processing video 112/200: 0048f391-eae6a189.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0048f391-eae6a189.mov\n",
            "🎬 Finished video 112/200: 0048f391-eae6a189.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 113/200: 00495359-1d04dd8a.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00495359-1d04dd8a.mov\n",
            "🎬 Finished video 113/200: 00495359-1d04dd8a.mov - Total frames processed: 313, Frames saved: 53\n",
            "🎬 Processing video 114/200: 00495359-27ce9c7e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00495359-27ce9c7e.mov\n",
            "🎬 Finished video 114/200: 00495359-27ce9c7e.mov - Total frames processed: 617, Frames saved: 103\n",
            "🎬 Processing video 115/200: 0049e5b8-725e21a0.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0049e5b8-725e21a0.mov\n",
            "🎬 Finished video 115/200: 0049e5b8-725e21a0.mov - Total frames processed: 1174, Frames saved: 196\n",
            "🎬 Processing video 116/200: 0049e5b8-afda7206.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0049e5b8-afda7206.mov\n",
            "🎬 Finished video 116/200: 0049e5b8-afda7206.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 117/200: 004ea016-0b1932a7.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/004ea016-0b1932a7.mov\n",
            "🎬 Finished video 117/200: 004ea016-0b1932a7.mov - Total frames processed: 1212, Frames saved: 203\n",
            "🎬 Processing video 118/200: 00516b75-7ac91661.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00516b75-7ac91661.mov\n",
            "🎬 Finished video 118/200: 00516b75-7ac91661.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 119/200: 0051e391-d32a618e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0051e391-d32a618e.mov\n",
            "🎬 Finished video 119/200: 0051e391-d32a618e.mov - Total frames processed: 1248, Frames saved: 209\n",
            "🎬 Processing video 120/200: 0052b279-87c692aa.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0052b279-87c692aa.mov\n",
            "🎬 Finished video 120/200: 0052b279-87c692aa.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 121/200: 005645a1-dbe34c9d.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/005645a1-dbe34c9d.mov\n",
            "🎬 Finished video 121/200: 005645a1-dbe34c9d.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 122/200: 00589f25-4cf2b9e0.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00589f25-4cf2b9e0.mov\n",
            "🎬 Finished video 122/200: 00589f25-4cf2b9e0.mov - Total frames processed: 1201, Frames saved: 201\n",
            "🎬 Processing video 123/200: 0059f17f-f0882eef.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0059f17f-f0882eef.mov\n",
            "🎬 Finished video 123/200: 0059f17f-f0882eef.mov - Total frames processed: 1206, Frames saved: 202\n",
            "🎬 Processing video 124/200: 005c4fd3-cb4d6287.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/005c4fd3-cb4d6287.mov\n",
            "🎬 Finished video 124/200: 005c4fd3-cb4d6287.mov - Total frames processed: 1190, Frames saved: 199\n",
            "🎬 Processing video 125/200: 005cdef0-180a776c.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/005cdef0-180a776c.mov\n",
            "🎬 Finished video 125/200: 005cdef0-180a776c.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 126/200: 005ee183-0100ac18.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/005ee183-0100ac18.mov\n",
            "🎬 Finished video 126/200: 005ee183-0100ac18.mov - Total frames processed: 1213, Frames saved: 203\n",
            "🎬 Processing video 127/200: 005ee183-bcfab89f.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/005ee183-bcfab89f.mov\n",
            "🎬 Finished video 127/200: 005ee183-bcfab89f.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 128/200: 005fd7be-d8e0dc65.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/005fd7be-d8e0dc65.mov\n",
            "🎬 Finished video 128/200: 005fd7be-d8e0dc65.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 129/200: 005ff190-5be4cdfa.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/005ff190-5be4cdfa.mov\n",
            "🎬 Finished video 129/200: 005ff190-5be4cdfa.mov - Total frames processed: 1213, Frames saved: 203\n",
            "🎬 Processing video 130/200: 0060b445-5acc00ed.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0060b445-5acc00ed.mov\n",
            "🎬 Finished video 130/200: 0060b445-5acc00ed.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 131/200: 00618cec-3bc5573e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00618cec-3bc5573e.mov\n",
            "🎬 Finished video 131/200: 00618cec-3bc5573e.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 132/200: 00618cec-a7f7e470.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00618cec-a7f7e470.mov\n",
            "🎬 Finished video 132/200: 00618cec-a7f7e470.mov - Total frames processed: 1206, Frames saved: 202\n",
            "🎬 Processing video 133/200: 00618cec-ef92ac05.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00618cec-ef92ac05.mov\n",
            "🎬 Finished video 133/200: 00618cec-ef92ac05.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 134/200: 0062298d-2d787502.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0062298d-2d787502.mov\n",
            "🎬 Finished video 134/200: 0062298d-2d787502.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 135/200: 0062298d-cbbec2cd.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0062298d-cbbec2cd.mov\n",
            "🎬 Finished video 135/200: 0062298d-cbbec2cd.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 136/200: 0062298d-e6abad2f.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0062298d-e6abad2f.mov\n",
            "🎬 Finished video 136/200: 0062298d-e6abad2f.mov - Total frames processed: 1211, Frames saved: 202\n",
            "🎬 Processing video 137/200: 0062298d-fd69d0ec.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0062298d-fd69d0ec.mov\n",
            "🎬 Finished video 137/200: 0062298d-fd69d0ec.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 138/200: 0062ab5a-54bb129b.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0062ab5a-54bb129b.mov\n",
            "🎬 Finished video 138/200: 0062ab5a-54bb129b.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 139/200: 0062e803-38c0a33a.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0062e803-38c0a33a.mov\n",
            "🎬 Finished video 139/200: 0062e803-38c0a33a.mov - Total frames processed: 611, Frames saved: 102\n",
            "🎬 Processing video 140/200: 0062f18d-f8cd3a65.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0062f18d-f8cd3a65.mov\n",
            "🎬 Finished video 140/200: 0062f18d-f8cd3a65.mov - Total frames processed: 606, Frames saved: 102\n",
            "🎬 Processing video 141/200: 006382a3-4a442001.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/006382a3-4a442001.mov\n",
            "🎬 Finished video 141/200: 006382a3-4a442001.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 142/200: 0065fe83-c80cf6c3.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0065fe83-c80cf6c3.mov\n",
            "🎬 Finished video 142/200: 0065fe83-c80cf6c3.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 143/200: 006676e5-0a512e75.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/006676e5-0a512e75.mov\n",
            "🎬 Finished video 143/200: 006676e5-0a512e75.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 144/200: 006676e5-624162a7.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/006676e5-624162a7.mov\n",
            "🎬 Finished video 144/200: 006676e5-624162a7.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 145/200: 0066b72f-974f6883.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0066b72f-974f6883.mov\n",
            "🎬 Finished video 145/200: 0066b72f-974f6883.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 146/200: 00690c26-e4bbbd72.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00690c26-e4bbbd72.mov\n",
            "🎬 Finished video 146/200: 00690c26-e4bbbd72.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 147/200: 00699de6-58847872.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00699de6-58847872.mov\n",
            "🎬 Finished video 147/200: 00699de6-58847872.mov - Total frames processed: 1202, Frames saved: 201\n",
            "🎬 Processing video 148/200: 006a4209-286a5664.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/006a4209-286a5664.mov\n",
            "🎬 Finished video 148/200: 006a4209-286a5664.mov - Total frames processed: 1162, Frames saved: 194\n",
            "🎬 Processing video 149/200: 006a4209-4f3bf6cf.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/006a4209-4f3bf6cf.mov\n",
            "🎬 Finished video 149/200: 006a4209-4f3bf6cf.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 150/200: 006a7635-c42f9f97.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/006a7635-c42f9f97.mov\n",
            "🎬 Finished video 150/200: 006a7635-c42f9f97.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 151/200: 006a7635-ec8fe02c.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/006a7635-ec8fe02c.mov\n",
            "🎬 Finished video 151/200: 006a7635-ec8fe02c.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 152/200: 006bb043-fe4bbaf6.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/006bb043-fe4bbaf6.mov\n",
            "🎬 Finished video 152/200: 006bb043-fe4bbaf6.mov - Total frames processed: 1194, Frames saved: 200\n",
            "🎬 Processing video 153/200: 006bff20-752bd845.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/006bff20-752bd845.mov\n",
            "🎬 Finished video 153/200: 006bff20-752bd845.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 154/200: 006c0799-10697723.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/006c0799-10697723.mov\n",
            "🎬 Finished video 154/200: 006c0799-10697723.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 155/200: 006c0799-964a2695.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/006c0799-964a2695.mov\n",
            "🎬 Finished video 155/200: 006c0799-964a2695.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 156/200: 006d6f8e-4759e8c1.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/006d6f8e-4759e8c1.mov\n",
            "🎬 Finished video 156/200: 006d6f8e-4759e8c1.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 157/200: 006dd004-34630e8d.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/006dd004-34630e8d.mov\n",
            "🎬 Finished video 157/200: 006dd004-34630e8d.mov - Total frames processed: 1213, Frames saved: 203\n",
            "🎬 Processing video 158/200: 006fdb67-526bb14e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/006fdb67-526bb14e.mov\n",
            "🎬 Finished video 158/200: 006fdb67-526bb14e.mov - Total frames processed: 1206, Frames saved: 202\n",
            "🎬 Processing video 159/200: 006fdb67-a1455b77.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/006fdb67-a1455b77.mov\n",
            "🎬 Finished video 159/200: 006fdb67-a1455b77.mov - Total frames processed: 1202, Frames saved: 201\n",
            "🎬 Processing video 160/200: 006fdb67-f4820206.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/006fdb67-f4820206.mov\n",
            "🎬 Finished video 160/200: 006fdb67-f4820206.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 161/200: 0070bc56-29bcc943.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0070bc56-29bcc943.mov\n",
            "🎬 Finished video 161/200: 0070bc56-29bcc943.mov - Total frames processed: 606, Frames saved: 102\n",
            "🎬 Processing video 162/200: 0070bc56-401304be.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0070bc56-401304be.mov\n",
            "🎬 Finished video 162/200: 0070bc56-401304be.mov - Total frames processed: 616, Frames saved: 103\n",
            "🎬 Processing video 163/200: 0070bc56-49cf077c.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0070bc56-49cf077c.mov\n",
            "🎬 Finished video 163/200: 0070bc56-49cf077c.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 164/200: 0070bc56-4c0bb2d5.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0070bc56-4c0bb2d5.mov\n",
            "🎬 Finished video 164/200: 0070bc56-4c0bb2d5.mov - Total frames processed: 609, Frames saved: 102\n",
            "🎬 Processing video 165/200: 0070bc56-7d01076a.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0070bc56-7d01076a.mov\n",
            "🎬 Finished video 165/200: 0070bc56-7d01076a.mov - Total frames processed: 1196, Frames saved: 200\n",
            "🎬 Processing video 166/200: 0070bc56-8d8cfd82.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0070bc56-8d8cfd82.mov\n",
            "🎬 Finished video 166/200: 0070bc56-8d8cfd82.mov - Total frames processed: 603, Frames saved: 101\n",
            "🎬 Processing video 167/200: 00714cd3-48d6b290.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00714cd3-48d6b290.mov\n",
            "🎬 Finished video 167/200: 00714cd3-48d6b290.mov - Total frames processed: 1212, Frames saved: 203\n",
            "🎬 Processing video 168/200: 0071d9c5-0f52d539.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0071d9c5-0f52d539.mov\n",
            "🎬 Finished video 168/200: 0071d9c5-0f52d539.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 169/200: 0071d9c5-be7394cc.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0071d9c5-be7394cc.mov\n",
            "🎬 Finished video 169/200: 0071d9c5-be7394cc.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 170/200: 00721168-56efa5c2.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00721168-56efa5c2.mov\n",
            "🎬 Finished video 170/200: 00721168-56efa5c2.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 171/200: 0075a5b0-9a8d5dbb.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0075a5b0-9a8d5dbb.mov\n",
            "🎬 Finished video 171/200: 0075a5b0-9a8d5dbb.mov - Total frames processed: 611, Frames saved: 102\n",
            "🎬 Processing video 172/200: 0075b179-8e09869a.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0075b179-8e09869a.mov\n",
            "🎬 Finished video 172/200: 0075b179-8e09869a.mov - Total frames processed: 1211, Frames saved: 202\n",
            "🎬 Processing video 173/200: 007693e6-2535e7bf.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007693e6-2535e7bf.mov\n",
            "🎬 Finished video 173/200: 007693e6-2535e7bf.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 174/200: 007693e6-bc55f0e4.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007693e6-bc55f0e4.mov\n",
            "🎬 Finished video 174/200: 007693e6-bc55f0e4.mov - Total frames processed: 1211, Frames saved: 202\n",
            "🎬 Processing video 175/200: 007693e6-c2a8b9a7.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007693e6-c2a8b9a7.mov\n",
            "🎬 Finished video 175/200: 007693e6-c2a8b9a7.mov - Total frames processed: 1171, Frames saved: 196\n",
            "🎬 Processing video 176/200: 00779058-517a4591.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00779058-517a4591.mov\n",
            "🎬 Finished video 176/200: 00779058-517a4591.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 177/200: 0077ccb8-d5778190.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0077ccb8-d5778190.mov\n",
            "🎬 Finished video 177/200: 0077ccb8-d5778190.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 178/200: 00787a90-b350f376.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00787a90-b350f376.mov\n",
            "🎬 Finished video 178/200: 00787a90-b350f376.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 179/200: 007ae77f-79995643.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007ae77f-79995643.mov\n",
            "🎬 Finished video 179/200: 007ae77f-79995643.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 180/200: 007aeb45-3e75ce0e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007aeb45-3e75ce0e.mov\n",
            "🎬 Finished video 180/200: 007aeb45-3e75ce0e.mov - Total frames processed: 1213, Frames saved: 203\n",
            "🎬 Processing video 181/200: 007aeb45-56d1aed9.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007aeb45-56d1aed9.mov\n",
            "🎬 Finished video 181/200: 007aeb45-56d1aed9.mov - Total frames processed: 1202, Frames saved: 201\n",
            "🎬 Processing video 182/200: 007aeb45-9330e852.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007aeb45-9330e852.mov\n",
            "🎬 Finished video 182/200: 007aeb45-9330e852.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 183/200: 007aeb45-96ce245e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007aeb45-96ce245e.mov\n",
            "🎬 Finished video 183/200: 007aeb45-96ce245e.mov - Total frames processed: 1206, Frames saved: 202\n",
            "🎬 Processing video 184/200: 007aeb45-c601742b.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007aeb45-c601742b.mov\n",
            "🎬 Finished video 184/200: 007aeb45-c601742b.mov - Total frames processed: 1260, Frames saved: 211\n",
            "🎬 Processing video 185/200: 007aeb45-eef41701.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007aeb45-eef41701.mov\n",
            "🎬 Finished video 185/200: 007aeb45-eef41701.mov - Total frames processed: 1202, Frames saved: 201\n",
            "🎬 Processing video 186/200: 007aeb45-f9f5ac8c.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007aeb45-f9f5ac8c.mov\n",
            "🎬 Finished video 186/200: 007aeb45-f9f5ac8c.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 187/200: 007b11e5-1033ff33.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007b11e5-1033ff33.mov\n",
            "🎬 Finished video 187/200: 007b11e5-1033ff33.mov - Total frames processed: 1214, Frames saved: 203\n",
            "🎬 Processing video 188/200: 007b11e5-c22ddae8.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007b11e5-c22ddae8.mov\n",
            "🎬 Finished video 188/200: 007b11e5-c22ddae8.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 189/200: 007c01ea-63aa326c.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007c01ea-63aa326c.mov\n",
            "🎬 Finished video 189/200: 007c01ea-63aa326c.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 190/200: 007c01ea-a02f29ef.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007c01ea-a02f29ef.mov\n",
            "🎬 Finished video 190/200: 007c01ea-a02f29ef.mov - Total frames processed: 1178, Frames saved: 197\n",
            "🎬 Processing video 191/200: 007c01ea-ad9f940b.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007c01ea-ad9f940b.mov\n",
            "🎬 Finished video 191/200: 007c01ea-ad9f940b.mov - Total frames processed: 612, Frames saved: 103\n",
            "🎬 Processing video 192/200: 007c11bf-f6da335c.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007c11bf-f6da335c.mov\n",
            "🎬 Finished video 192/200: 007c11bf-f6da335c.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 193/200: 007da0eb-1bad8468.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007da0eb-1bad8468.mov\n",
            "🎬 Finished video 193/200: 007da0eb-1bad8468.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 194/200: 007da0eb-8cca23d7.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007da0eb-8cca23d7.mov\n",
            "🎬 Finished video 194/200: 007da0eb-8cca23d7.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 195/200: 007da0eb-e1f588e8.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007da0eb-e1f588e8.mov\n",
            "🎬 Finished video 195/200: 007da0eb-e1f588e8.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 196/200: 007eddfc-528c4da4.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007eddfc-528c4da4.mov\n",
            "🎬 Finished video 196/200: 007eddfc-528c4da4.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 197/200: 007eddfc-bcaeb35b.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007eddfc-bcaeb35b.mov\n",
            "🎬 Finished video 197/200: 007eddfc-bcaeb35b.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 198/200: 007eddfc-f8a80310.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/007eddfc-f8a80310.mov\n",
            "🎬 Finished video 198/200: 007eddfc-f8a80310.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 199/200: 0080b637-55f7930e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0080b637-55f7930e.mov\n",
            "🎬 Finished video 199/200: 0080b637-55f7930e.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 200/200: 00810e80-37641274.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00810e80-37641274.mov\n",
            "🎬 Finished video 200/200: 00810e80-37641274.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 1/100: 0081c36b-30bff234.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0081c36b-30bff234.mov\n",
            "🎬 Finished video 1/100: 0081c36b-30bff234.mov - Total frames processed: 1201, Frames saved: 201\n",
            "🎬 Processing video 2/100: 0081da60-27997c07.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0081da60-27997c07.mov\n",
            "🎬 Finished video 2/100: 0081da60-27997c07.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 3/100: 0081da60-5fa22cc6.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0081da60-5fa22cc6.mov\n",
            "🎬 Finished video 3/100: 0081da60-5fa22cc6.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 4/100: 0081e27b-17bf4a9e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0081e27b-17bf4a9e.mov\n",
            "🎬 Finished video 4/100: 0081e27b-17bf4a9e.mov - Total frames processed: 1215, Frames saved: 203\n",
            "🎬 Processing video 5/100: 0081e3ea-2c0ec19d.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0081e3ea-2c0ec19d.mov\n",
            "🎬 Finished video 5/100: 0081e3ea-2c0ec19d.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 6/100: 0081e3ea-3f7b0282.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0081e3ea-3f7b0282.mov\n",
            "🎬 Finished video 6/100: 0081e3ea-3f7b0282.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 7/100: 0081e3ea-4551210e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0081e3ea-4551210e.mov\n",
            "🎬 Finished video 7/100: 0081e3ea-4551210e.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 8/100: 0081e3ea-9f5dda4a.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0081e3ea-9f5dda4a.mov\n",
            "🎬 Finished video 8/100: 0081e3ea-9f5dda4a.mov - Total frames processed: 1216, Frames saved: 203\n",
            "🎬 Processing video 9/100: 0081e3ea-b9448b6b.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0081e3ea-b9448b6b.mov\n",
            "🎬 Finished video 9/100: 0081e3ea-b9448b6b.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 10/100: 0081e3ea-cc69a1c4.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0081e3ea-cc69a1c4.mov\n",
            "🎬 Finished video 10/100: 0081e3ea-cc69a1c4.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 11/100: 00825605-9dcec7d0.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00825605-9dcec7d0.mov\n",
            "🎬 Finished video 11/100: 00825605-9dcec7d0.mov - Total frames processed: 1197, Frames saved: 200\n",
            "🎬 Processing video 12/100: 00831388-d801f28b.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00831388-d801f28b.mov\n",
            "🎬 Finished video 12/100: 00831388-d801f28b.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 13/100: 00852c8f-14cf1e60.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00852c8f-14cf1e60.mov\n",
            "🎬 Finished video 13/100: 00852c8f-14cf1e60.mov - Total frames processed: 1206, Frames saved: 202\n",
            "🎬 Processing video 14/100: 0088cf04-319858ad.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0088cf04-319858ad.mov\n",
            "🎬 Finished video 14/100: 0088cf04-319858ad.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 15/100: 0089bc2f-5f2d57d5.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0089bc2f-5f2d57d5.mov\n",
            "🎬 Finished video 15/100: 0089bc2f-5f2d57d5.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 16/100: 008d2a0a-ac995caf.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/008d2a0a-ac995caf.mov\n",
            "🎬 Finished video 16/100: 008d2a0a-ac995caf.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 17/100: 008db5fb-223715d5.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/008db5fb-223715d5.mov\n",
            "🎬 Finished video 17/100: 008db5fb-223715d5.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 18/100: 008dd3b9-4b6790d5.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/008dd3b9-4b6790d5.mov\n",
            "🎬 Finished video 18/100: 008dd3b9-4b6790d5.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 19/100: 008edf63-4a001f1b.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/008edf63-4a001f1b.mov\n",
            "🎬 Finished video 19/100: 008edf63-4a001f1b.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 20/100: 008edf63-51af8ab6.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/008edf63-51af8ab6.mov\n",
            "🎬 Finished video 20/100: 008edf63-51af8ab6.mov - Total frames processed: 1213, Frames saved: 203\n",
            "🎬 Processing video 21/100: 0090c713-2854b392.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0090c713-2854b392.mov\n",
            "🎬 Finished video 21/100: 0090c713-2854b392.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 22/100: 0090c713-683fc99a.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0090c713-683fc99a.mov\n",
            "🎬 Finished video 22/100: 0090c713-683fc99a.mov - Total frames processed: 1214, Frames saved: 203\n",
            "🎬 Processing video 23/100: 0090c713-9d58a186.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0090c713-9d58a186.mov\n",
            "🎬 Finished video 23/100: 0090c713-9d58a186.mov - Total frames processed: 1197, Frames saved: 200\n",
            "🎬 Processing video 24/100: 009215e2-62d79d70.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/009215e2-62d79d70.mov\n",
            "🎬 Finished video 24/100: 009215e2-62d79d70.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 25/100: 009215e2-8500bd0b.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/009215e2-8500bd0b.mov\n",
            "🎬 Finished video 25/100: 009215e2-8500bd0b.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 26/100: 009215e2-d6d2d61b.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/009215e2-d6d2d61b.mov\n",
            "🎬 Finished video 26/100: 009215e2-d6d2d61b.mov - Total frames processed: 1212, Frames saved: 203\n",
            "🎬 Processing video 27/100: 009215e2-e67ccfb7.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/009215e2-e67ccfb7.mov\n",
            "🎬 Finished video 27/100: 009215e2-e67ccfb7.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 28/100: 009215e2-ea063b28.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/009215e2-ea063b28.mov\n",
            "🎬 Finished video 28/100: 009215e2-ea063b28.mov - Total frames processed: 1204, Frames saved: 201\n",
            "🎬 Processing video 29/100: 0092e44c-3b3dee4b.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0092e44c-3b3dee4b.mov\n",
            "🎬 Finished video 29/100: 0092e44c-3b3dee4b.mov - Total frames processed: 1212, Frames saved: 203\n",
            "🎬 Processing video 30/100: 0094ffe5-596e38bd.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0094ffe5-596e38bd.mov\n",
            "🎬 Finished video 30/100: 0094ffe5-596e38bd.mov - Total frames processed: 1212, Frames saved: 203\n",
            "🎬 Processing video 31/100: 0096bcca-095d2c02.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0096bcca-095d2c02.mov\n",
            "🎬 Finished video 31/100: 0096bcca-095d2c02.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 32/100: 0096bcca-27a61cb3.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0096bcca-27a61cb3.mov\n",
            "🎬 Finished video 32/100: 0096bcca-27a61cb3.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 33/100: 0096bcca-369281bd.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0096bcca-369281bd.mov\n",
            "🎬 Finished video 33/100: 0096bcca-369281bd.mov - Total frames processed: 1204, Frames saved: 201\n",
            "🎬 Processing video 34/100: 0096bcca-42d2702c.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0096bcca-42d2702c.mov\n",
            "🎬 Finished video 34/100: 0096bcca-42d2702c.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 35/100: 0096bcca-81ffedfc.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0096bcca-81ffedfc.mov\n",
            "🎬 Finished video 35/100: 0096bcca-81ffedfc.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 36/100: 0096bcca-a25719cb.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0096bcca-a25719cb.mov\n",
            "🎬 Finished video 36/100: 0096bcca-a25719cb.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 37/100: 0096bcca-bfb5ea6c.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0096bcca-bfb5ea6c.mov\n",
            "🎬 Finished video 37/100: 0096bcca-bfb5ea6c.mov - Total frames processed: 1213, Frames saved: 203\n",
            "🎬 Processing video 38/100: 0096bcca-c2027ec4.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0096bcca-c2027ec4.mov\n",
            "🎬 Finished video 38/100: 0096bcca-c2027ec4.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 39/100: 0096bcca-fc7d6d3c.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0096bcca-fc7d6d3c.mov\n",
            "🎬 Finished video 39/100: 0096bcca-fc7d6d3c.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 40/100: 0096f810-6bcc27da.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/0096f810-6bcc27da.mov\n",
            "🎬 Finished video 40/100: 0096f810-6bcc27da.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 41/100: 00982f76-83a093ef.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00982f76-83a093ef.mov\n",
            "🎬 Finished video 41/100: 00982f76-83a093ef.mov - Total frames processed: 1202, Frames saved: 201\n",
            "🎬 Processing video 42/100: 009aecce-ab411438.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/009aecce-ab411438.mov\n",
            "🎬 Finished video 42/100: 009aecce-ab411438.mov - Total frames processed: 1216, Frames saved: 203\n",
            "🎬 Processing video 43/100: 009aecce-ce4a9413.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/009aecce-ce4a9413.mov\n",
            "🎬 Finished video 43/100: 009aecce-ce4a9413.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 44/100: 009b0eb2-bbef939f.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/009b0eb2-bbef939f.mov\n",
            "🎬 Finished video 44/100: 009b0eb2-bbef939f.mov - Total frames processed: 1200, Frames saved: 201\n",
            "🎬 Processing video 45/100: 009b6a87-b15675e2.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/009b6a87-b15675e2.mov\n",
            "🎬 Finished video 45/100: 009b6a87-b15675e2.mov - Total frames processed: 1211, Frames saved: 202\n",
            "🎬 Processing video 46/100: 009bd04d-0f1f9967.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/009bd04d-0f1f9967.mov\n",
            "🎬 Finished video 46/100: 009bd04d-0f1f9967.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 47/100: 009bd04d-42445981.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/009bd04d-42445981.mov\n",
            "🎬 Finished video 47/100: 009bd04d-42445981.mov - Total frames processed: 1202, Frames saved: 201\n",
            "🎬 Processing video 48/100: 009c662e-91aa5a86.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/009c662e-91aa5a86.mov\n",
            "🎬 Finished video 48/100: 009c662e-91aa5a86.mov - Total frames processed: 1213, Frames saved: 203\n",
            "🎬 Processing video 49/100: 009deddd-c8963379.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/009deddd-c8963379.mov\n",
            "🎬 Finished video 49/100: 009deddd-c8963379.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 50/100: 009deddd-d68ff1f7.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/009deddd-d68ff1f7.mov\n",
            "🎬 Finished video 50/100: 009deddd-d68ff1f7.mov - Total frames processed: 1204, Frames saved: 201\n",
            "🎬 Processing video 51/100: 009e7a6a-3d755b8b.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/009e7a6a-3d755b8b.mov\n",
            "🎬 Finished video 51/100: 009e7a6a-3d755b8b.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 52/100: 00a04f65-8c891f94.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00a04f65-8c891f94.mov\n",
            "🎬 Finished video 52/100: 00a04f65-8c891f94.mov - Total frames processed: 1213, Frames saved: 203\n",
            "🎬 Processing video 53/100: 00a04f65-af2ab984.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00a04f65-af2ab984.mov\n",
            "🎬 Finished video 53/100: 00a04f65-af2ab984.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 54/100: 00a0f008-3c67908e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00a0f008-3c67908e.mov\n",
            "🎬 Finished video 54/100: 00a0f008-3c67908e.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 55/100: 00a0f008-a315437f.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00a0f008-a315437f.mov\n",
            "🎬 Finished video 55/100: 00a0f008-a315437f.mov - Total frames processed: 1214, Frames saved: 203\n",
            "🎬 Processing video 56/100: 00a1176f-0652080e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00a1176f-0652080e.mov\n",
            "🎬 Finished video 56/100: 00a1176f-0652080e.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 57/100: 00a1176f-5121b501.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00a1176f-5121b501.mov\n",
            "🎬 Finished video 57/100: 00a1176f-5121b501.mov - Total frames processed: 1211, Frames saved: 202\n",
            "🎬 Processing video 58/100: 00a2e3ca-5c856cde.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00a2e3ca-5c856cde.mov\n",
            "🎬 Finished video 58/100: 00a2e3ca-5c856cde.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 59/100: 00a2e3ca-62992459.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00a2e3ca-62992459.mov\n",
            "🎬 Finished video 59/100: 00a2e3ca-62992459.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 60/100: 00a2f5b6-d4217a96.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00a2f5b6-d4217a96.mov\n",
            "🎬 Finished video 60/100: 00a2f5b6-d4217a96.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 61/100: 00a395fe-d60c0b47.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00a395fe-d60c0b47.mov\n",
            "🎬 Finished video 61/100: 00a395fe-d60c0b47.mov - Total frames processed: 1211, Frames saved: 202\n",
            "🎬 Processing video 62/100: 00a820ef-2b98dcf5.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00a820ef-2b98dcf5.mov\n",
            "🎬 Finished video 62/100: 00a820ef-2b98dcf5.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 63/100: 00a820ef-98a12e22.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00a820ef-98a12e22.mov\n",
            "🎬 Finished video 63/100: 00a820ef-98a12e22.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 64/100: 00a820ef-d655700e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00a820ef-d655700e.mov\n",
            "🎬 Finished video 64/100: 00a820ef-d655700e.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 65/100: 00a9cd6b-b39be004.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00a9cd6b-b39be004.mov\n",
            "🎬 Finished video 65/100: 00a9cd6b-b39be004.mov - Total frames processed: 1212, Frames saved: 203\n",
            "🎬 Processing video 66/100: 00abd8a7-ecd6fc56.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00abd8a7-ecd6fc56.mov\n",
            "🎬 Finished video 66/100: 00abd8a7-ecd6fc56.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 67/100: 00abf44e-04004ca0.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00abf44e-04004ca0.mov\n",
            "🎬 Finished video 67/100: 00abf44e-04004ca0.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 68/100: 00abf44e-421f6ed7.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00abf44e-421f6ed7.mov\n",
            "🎬 Finished video 68/100: 00abf44e-421f6ed7.mov - Total frames processed: 1208, Frames saved: 202\n",
            "🎬 Processing video 69/100: 00ac3256-0f8e2cda.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00ac3256-0f8e2cda.mov\n",
            "🎬 Finished video 69/100: 00ac3256-0f8e2cda.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 70/100: 00ad8a92-c4851839.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00ad8a92-c4851839.mov\n",
            "🎬 Finished video 70/100: 00ad8a92-c4851839.mov - Total frames processed: 1212, Frames saved: 203\n",
            "🎬 Processing video 71/100: 00adbb3f-7757d4ea.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00adbb3f-7757d4ea.mov\n",
            "🎬 Finished video 71/100: 00adbb3f-7757d4ea.mov - Total frames processed: 1204, Frames saved: 201\n",
            "🎬 Processing video 72/100: 00afa5b2-c14a542f.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00afa5b2-c14a542f.mov\n",
            "🎬 Finished video 72/100: 00afa5b2-c14a542f.mov - Total frames processed: 1207, Frames saved: 202\n",
            "🎬 Processing video 73/100: 00afa6b9-4efe0141.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00afa6b9-4efe0141.mov\n",
            "🎬 Finished video 73/100: 00afa6b9-4efe0141.mov - Total frames processed: 1213, Frames saved: 203\n",
            "🎬 Processing video 74/100: 00b04b12-a7d7eb85.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00b04b12-a7d7eb85.mov\n",
            "🎬 Finished video 74/100: 00b04b12-a7d7eb85.mov - Total frames processed: 1205, Frames saved: 201\n",
            "🎬 Processing video 75/100: 00b04b30-2e874876.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00b04b30-2e874876.mov\n",
            "🎬 Finished video 75/100: 00b04b30-2e874876.mov - Total frames processed: 611, Frames saved: 102\n",
            "🎬 Processing video 76/100: 00b04b30-501822fa.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00b04b30-501822fa.mov\n",
            "🎬 Finished video 76/100: 00b04b30-501822fa.mov - Total frames processed: 596, Frames saved: 100\n",
            "🎬 Processing video 77/100: 00b1dfed-a89dbe2b.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00b1dfed-a89dbe2b.mov\n",
            "🎬 Finished video 77/100: 00b1dfed-a89dbe2b.mov - Total frames processed: 1212, Frames saved: 203\n",
            "🎬 Processing video 78/100: 00b4c5fc-8fcf3628.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00b4c5fc-8fcf3628.mov\n",
            "🎬 Finished video 78/100: 00b4c5fc-8fcf3628.mov - Total frames processed: 1212, Frames saved: 203\n",
            "🎬 Processing video 79/100: 00b56f41-e0e5d918.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00b56f41-e0e5d918.mov\n",
            "🎬 Finished video 79/100: 00b56f41-e0e5d918.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 80/100: 00b93c6e-6298aa25.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00b93c6e-6298aa25.mov\n",
            "🎬 Finished video 80/100: 00b93c6e-6298aa25.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 81/100: 00be7020-457a6db4.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00be7020-457a6db4.mov\n",
            "🎬 Finished video 81/100: 00be7020-457a6db4.mov - Total frames processed: 607, Frames saved: 102\n",
            "🎬 Processing video 82/100: 00beeb02-50440dcd.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00beeb02-50440dcd.mov\n",
            "🎬 Finished video 82/100: 00beeb02-50440dcd.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 83/100: 00beeb02-ba0790aa.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00beeb02-ba0790aa.mov\n",
            "🎬 Finished video 83/100: 00beeb02-ba0790aa.mov - Total frames processed: 1212, Frames saved: 203\n",
            "🎬 Processing video 84/100: 00c12bd0-bb46e479.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00c12bd0-bb46e479.mov\n",
            "🎬 Finished video 84/100: 00c12bd0-bb46e479.mov - Total frames processed: 1212, Frames saved: 203\n",
            "🎬 Processing video 85/100: 00c17a92-d4803287.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00c17a92-d4803287.mov\n",
            "🎬 Finished video 85/100: 00c17a92-d4803287.mov - Total frames processed: 1206, Frames saved: 202\n",
            "🎬 Processing video 86/100: 00c29c52-f9524f1e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00c29c52-f9524f1e.mov\n",
            "🎬 Finished video 86/100: 00c29c52-f9524f1e.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 87/100: 00c41a61-4ba25ad4.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00c41a61-4ba25ad4.mov\n",
            "🎬 Finished video 87/100: 00c41a61-4ba25ad4.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 88/100: 00c497ae-595d361b.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00c497ae-595d361b.mov\n",
            "🎬 Finished video 88/100: 00c497ae-595d361b.mov - Total frames processed: 1203, Frames saved: 201\n",
            "🎬 Processing video 89/100: 00c4c672-26d36ad8.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00c4c672-26d36ad8.mov\n",
            "🎬 Finished video 89/100: 00c4c672-26d36ad8.mov - Total frames processed: 1213, Frames saved: 203\n",
            "🎬 Processing video 90/100: 00c50078-6298b9c1.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00c50078-6298b9c1.mov\n",
            "🎬 Finished video 90/100: 00c50078-6298b9c1.mov - Total frames processed: 1202, Frames saved: 201\n",
            "🎬 Processing video 91/100: 00c87627-b7f6f46c.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00c87627-b7f6f46c.mov\n",
            "🎬 Finished video 91/100: 00c87627-b7f6f46c.mov - Total frames processed: 1209, Frames saved: 202\n",
            "🎬 Processing video 92/100: 00ca8821-17667a58.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00ca8821-17667a58.mov\n",
            "🎬 Finished video 92/100: 00ca8821-17667a58.mov - Total frames processed: 1192, Frames saved: 199\n",
            "🎬 Processing video 93/100: 00ca8821-db8033d5.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00ca8821-db8033d5.mov\n",
            "🎬 Finished video 93/100: 00ca8821-db8033d5.mov - Total frames processed: 1210, Frames saved: 202\n",
            "🎬 Processing video 94/100: 00cb28b9-08a22af7.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00cb28b9-08a22af7.mov\n",
            "🎬 Finished video 94/100: 00cb28b9-08a22af7.mov - Total frames processed: 1206, Frames saved: 202\n",
            "🎬 Processing video 95/100: 00ccf2e8-59a6bfc9.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00ccf2e8-59a6bfc9.mov\n",
            "🎬 Finished video 95/100: 00ccf2e8-59a6bfc9.mov - Total frames processed: 1211, Frames saved: 202\n",
            "🎬 Processing video 96/100: 00ccf2e8-ac055be6.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00ccf2e8-ac055be6.mov\n",
            "🎬 Finished video 96/100: 00ccf2e8-ac055be6.mov - Total frames processed: 1213, Frames saved: 203\n",
            "🎬 Processing video 97/100: 00ccf2e8-f8c69860.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00ccf2e8-f8c69860.mov\n",
            "🎬 Finished video 97/100: 00ccf2e8-f8c69860.mov - Total frames processed: 1212, Frames saved: 203\n",
            "🎬 Processing video 98/100: 00ce6f6d-50bbee62.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00ce6f6d-50bbee62.mov\n",
            "🎬 Finished video 98/100: 00ce6f6d-50bbee62.mov - Total frames processed: 1194, Frames saved: 200\n",
            "🎬 Processing video 99/100: 00ce8219-12c6d905.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00ce8219-12c6d905.mov\n",
            "🎬 Finished video 99/100: 00ce8219-12c6d905.mov - Total frames processed: 1191, Frames saved: 199\n",
            "🎬 Processing video 100/100: 00ce8219-d0b5582e.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/00ce8219-d0b5582e.mov\n",
            "🎬 Finished video 100/100: 00ce8219-d0b5582e.mov - Total frames processed: 1205, Frames saved: 201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{img_test_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5yFFfA2HSxO",
        "outputId": "4aef3e46-1b67-4d62-9218-5342a5791c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_yolov11n/images/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(img_train_dir)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8lFmkGVHoU2",
        "outputId": "4ba33bf7-8af7-4da3-d56b-2a38532fe4f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(img_test_dir)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JE2ey8xHw4f",
        "outputId": "785fcfcd-f35d-4b28-dfb8-752fed371d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_videos_subset = video_files[:300]\n",
        "test_videos_subset = video_files[300:400]"
      ],
      "metadata": {
        "id": "c3hd_AYPuCzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf {img_train_dir}+\"000d4f89-3bcbe37a.mov\""
      ],
      "metadata": {
        "id": "hIk0F2XWuIgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_file_1 = \"000d35d3-41990aa4.mov\"\n",
        "extract_frames([video_file_1], img_train_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUKvue1LtyuM",
        "outputId": "d1e79132-7438-413c-99b0-4ed45d27ce5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎬 Processing video 1/1: 000d35d3-41990aa4.mov\n",
            "vid_path: /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/000d35d3-41990aa4.mov\n",
            "🎬 Finished video 1/1: 000d35d3-41990aa4.mov - Total frames processed: 1203, Frames saved: 201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGo_83nrkGCt"
      },
      "outputs": [],
      "source": [
        "#Process all .mov videos\n",
        "video_files = sorted([f for f in os.listdir(video_dir) if f.lower().endswith(\".mov\")])\n",
        "num_videos = len(video_files)\n",
        "print(f\"\\n🎞️ Found {num_videos} .mov files.\")\n",
        "\n",
        "# Iterate through all video files\n",
        "for i, video_file in enumerate(video_files):\n",
        "    vid_path = os.path.join(video_dir, video_file)\n",
        "    vid_name = os.path.splitext(video_file)[0]\n",
        "    print(f\"\\r🎬 Processing video {i + 1}/{num_videos}: {video_file}\", end=\"\")\n",
        "\n",
        "    cap = cv2.VideoCapture(vid_path)\n",
        "    frame_id = 0\n",
        "    saved_frame_count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Save only every 6th frame\n",
        "        if frame_id % 6 == 0:\n",
        "            fname = f\"{vid_name}_frame_{frame_id:05d}.jpg\"\n",
        "            rotated_img = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
        "            cv2.imwrite(os.path.join(img_dir, fname), rotated_img)\n",
        "            saved_frame_count += 1\n",
        "            print(f\"\\r🎬 Processing video {i + 1}/{num_videos}: {video_file} - Saved Frame {frame_id:05d}\", end=\"\")\n",
        "        frame_id += 1\n",
        "\n",
        "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    print(f\"\\r🎬 Finished video {i + 1}/{num_videos}: {video_file} - Total frames processed: {num_frames}, Frames saved: {saved_frame_count}\")\n",
        "\n",
        "    cap.release()\n",
        "    break;"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_files = sorted([f for f in os.listdir(video_dir) if f.lower().endswith(\".mov\")])\n",
        "print(f\"\\n🎞️ Found {len(video_files)} .mov files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSy81jvo-dFz",
        "outputId": "ad32fb45-d082-400e-e15f-b0b10bcd9091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎞️ Found 1000 .mov files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'your_video_name' with the actual video name you want to count\n",
        "video_name_to_count = '00adbb3f-7757d4ea' # Example video name\n",
        "\n",
        "# Filter the DataFrame for the specified video name\n",
        "video_df = df[df['videoName'] == video_name_to_count]\n",
        "\n",
        "# Count the number of unique frameIndex values in the filtered DataFrame\n",
        "unique_frame_count = video_df['frameIndex'].nunique()\n",
        "\n",
        "print(f\"The number of unique frame IDs for video '{video_name_to_count}' is: {unique_frame_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yofMV0x9ngu",
        "outputId": "72153b28-e68d-4635-b056-4f5ebe357c37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of unique frame IDs for video '00adbb3f-7757d4ea' is: 202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'your_video_name' with the actual video name you want to count\n",
        "video_name_to_count_1 = '000d35d3-41990aa4' # Example video name\n",
        "\n",
        "# Filter the DataFrame for the specified video name\n",
        "video_df_1 = df[df['videoName'] == video_name_to_count_1]\n",
        "\n",
        "# Count the number of unique frameIndex values in the filtered DataFrame\n",
        "unique_frame_count_1 = video_df_1['frameIndex'].nunique()\n",
        "\n",
        "print(f\"The number of unique frame IDs for video '{video_name_to_count_1}' is: {unique_frame_count_1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la90u9oq1SSX",
        "outputId": "3b672b96-019a-48cc-d01a-1827c63019a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of unique frame IDs for video '000d35d3-41990aa4' is: 202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolo11n.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYxfwMMdAiLD",
        "outputId": "f0ed603d-b387-4644-ddca-4d6645648e4f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 101MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FdqYjSmpAk8d",
        "outputId": "dbfb1ad3-6821-4ef1-e7de-ca173aa466d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLO11n summary: 181 layers, 2,624,080 parameters, 0 gradients, 6.6 GFLOPs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(181, 2624080, 0, 6.614336)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!exiftool -Rotation video_files[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enSVetyKFK2M",
        "outputId": "5ad02b72-8def-4eb2-9d23-c99ca66b5bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: exiftool: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dREtdog5ttUq"
      },
      "outputs": [],
      "source": [
        "# FFmpeg-based hybrid frame extraction function\n",
        "import subprocess\n",
        "frame_interval = 10  # Nth frame to extract alongside I-frames\n",
        "\n",
        "def extract_video_frames(video_filename):\n",
        "    input_path = os.path.join(video_dir, video_filename)\n",
        "    video_name = os.path.splitext(video_filename)[0]\n",
        "    base_pattern = os.path.join(img_dir, f\"{video_name}_frame\")\n",
        "\n",
        "    # Extract I-frames\n",
        "    i_cmd = f\"\"\"\n",
        "    ffmpeg -y -skip_frame nokey -i \"{input_path}\" -vsync 0 -q:v 2 \\\n",
        "    \"{base_pattern}_I_%05d.jpg\"\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract every Nth frame\n",
        "    nth_cmd = f\"\"\"\n",
        "    ffmpeg -y -i \"{input_path}\" -vf \"select='not(mod(n\\\\,{frame_interval}))'\" \\\n",
        "    -vsync 0 -q:v 2 \"{base_pattern}_N_%05d.jpg\"\n",
        "    \"\"\"\n",
        "\n",
        "    env = os.environ.copy()\n",
        "    subprocess.run(i_cmd, shell=True, env=env, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    subprocess.run(nth_cmd, shell=True, env=env, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "adHkuCRfuBxU",
        "outputId": "297f3853-8777-45ff-c797-949278cca6df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Extracting from 1000 videos using 2 workers...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-3957062334.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n🚀 Extracting from {len(video_files)} videos using {cpu_count()} workers...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_video_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         '''\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Parallel frame extraction\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "# Parallel processing for frame extraction\n",
        "if __name__ == \"__main__\":\n",
        "    video_files = sorted([f for f in os.listdir(video_dir) if f.lower().endswith(\".mov\")])\n",
        "    print(f\"\\n🚀 Extracting from {len(video_files)} videos using {cpu_count()} workers...\")\n",
        "    with Pool(processes=cpu_count()) as pool:\n",
        "        pool.map(extract_video_frames, video_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5DBwCB6N2FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a2da7f-4b82-4cd5-bb24-89f5a3e215f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📄 Converting annotations to YOLO format...\n",
            "✅ Annotation conversion and saving complete.\n",
            "Total labels processed: 2890846\n",
            "Labels saved to train directory: 369410\n",
            "Labels saved to test directory: 188205\n",
            "Labels without matching video in subsets: 2329301\n"
          ]
        }
      ],
      "source": [
        "num_train_labels = 0\n",
        "num_test_labels = 0\n",
        "num_labels_without_match = 0\n",
        "\n",
        "# Convert annotations to YOLO format\n",
        "print(\"📄 Converting annotations to YOLO format...\")\n",
        "\n",
        "# Remove extension from subset video names for matching\n",
        "train_videos_subset_no_ext = {os.path.splitext(v)[0] for v in video_files[:200]}\n",
        "test_videos_subset_no_ext = {os.path.splitext(v)[0] for v in video_files[200:300]}\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    vname = row[\"videoName\"]\n",
        "    frame = int(row[\"frameIndex\"])\n",
        "    cls = row[\"category\"]\n",
        "    class_id = class_map.get(cls, -1)\n",
        "    if class_id == -1:\n",
        "        continue\n",
        "\n",
        "    x1, x2 = float(row[\"box2d.x1\"]), float(row[\"box2d.x2\"])\n",
        "    y1, y2 = float(row[\"box2d.y1\"]), float(row[\"box2d.y2\"])\n",
        "\n",
        "    xc = ((x1 + x2) / 2) / image_width\n",
        "    yc = ((y1 + y2) / 2) / image_height\n",
        "    w = (x2 - x1) / image_width\n",
        "    h = (y2 - y1) / image_height\n",
        "\n",
        "    # Determine the output directory (train or test)\n",
        "    if vname in train_videos_subset_no_ext:\n",
        "        label_dir = label_train_dir\n",
        "        num_train_labels += 1\n",
        "    elif vname in test_videos_subset_no_ext:\n",
        "        label_dir = label_test_dir\n",
        "        num_test_labels += 1\n",
        "    else:\n",
        "        # This case should ideally not happen if all videos in df are in train_videos or test_videos\n",
        "        num_labels_without_match += 1\n",
        "        continue\n",
        "\n",
        "    # Construct the label file path\n",
        "    label_path = os.path.join(label_dir, f\"{vname}_frame_{frame:05d}.txt\")\n",
        "    with open(label_path, \"a\") as f:\n",
        "        f.write(f\"{class_id} {xc:.6f} {yc:.6f} {w:.6f} {h:.6f}\\n\")\n",
        "\n",
        "print(\"✅ Annotation conversion and saving complete.\")\n",
        "print(f\"Total labels processed: {len(df)}\")\n",
        "print(f\"Labels saved to train directory: {num_train_labels}\")\n",
        "print(f\"Labels saved to test directory: {num_test_labels}\")\n",
        "print(f\"Labels without matching video in subsets: {num_labels_without_match}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YjXj3L6DN-Wo"
      },
      "outputs": [],
      "source": [
        "# Write YOLO dataset config\n",
        "yaml_path = \"bdd_dataset.yaml\"\n",
        "with open(yaml_path, \"w\") as f:\n",
        "    f.write(f\"\"\"\n",
        "path: {output_dir}\n",
        "train: images/train\n",
        "val: images/test\n",
        "nc: {len(class_map_combined)}\n",
        "names: {list(class_map_combined.keys())}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train YOLOv11-nano\n",
        "print(\"\\n🎯 Beginning model training...\")\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "start = time.time()\n",
        "model.train(data=yaml_path, epochs=40, imgsz=960, batch=-1, patience=20)\n",
        "end = time.time()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YgJNi7vvAQpA",
        "outputId": "39ea6a08-04f5-4905-ba4c-0dee126ff9e7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🎯 Beginning model training...\n",
            "Ultralytics 8.3.170 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=bdd_dataset.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=40, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=960, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=16\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    433792  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n",
            "YOLO11n summary: 181 layers, 2,592,960 parameters, 2,592,944 gradients, 6.5 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.4±0.1 ms, read: 263.1±126.6 MB/s, size: 365.6 KB)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_yolov11n/labels/train.cache... 62846 images, 1372 backgrounds, 1 corrupt: 100%|██████████| 64177/64177 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_yolov11n/images/train/idd_highquality_16k_15-07-18-upload_0017291.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.4723      1.3486]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=960 at 60.0% CUDA memory utilization.\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA A100-SXM4-40GB) 39.56G total, 13.09G reserved, 1.69G allocated, 24.78G free\n",
            "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
            "     2592960       14.53         4.490         36.11         51.46        (1, 3, 960, 960)                    list\n",
            "     2592960       29.06         4.752         31.78         36.44        (2, 3, 960, 960)                    list\n",
            "     2592960       58.11         5.557          33.9         33.71        (4, 3, 960, 960)                    list\n",
            "     2592960       116.2         7.262         37.68         41.63        (8, 3, 960, 960)                    list\n",
            "     2592960       232.4        10.393         41.42         54.83       (16, 3, 960, 960)                    list\n",
            "     2592960       464.9        16.165         58.93         101.7       (32, 3, 960, 960)                    list\n",
            "     2592960       929.8        28.200         116.2           196       (64, 3, 960, 960)                    list\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 28 for CUDA:0 29.46G/39.56G (74%) ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.3±0.0 ms, read: 119.8±87.1 MB/s, size: 265.0 KB)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_yolov11n/labels/train.cache... 62846 images, 1372 backgrounds, 1 corrupt: 100%|██████████| 64177/64177 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_yolov11n/images/train/idd_highquality_16k_15-07-18-upload_0017291.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.4723      1.3486]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.5±0.1 ms, read: 123.4±31.3 MB/s, size: 228.8 KB)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_yolov11n/labels/test.cache... 20488 images, 770 backgrounds, 0 corrupt: 100%|██████████| 21258/21258 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_yolov11n/images/test/idd_highquality_16k_HYD-2018-08-24_13-22-50_0007776.jpg: 1 duplicate labels removed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs/detect/train3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0004375), 87 bias(decay=0.0)\n",
            "Image sizes 960 train, 960 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
            "Starting training for 40 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/40      17.6G      1.544      1.931      1.282        406        960: 100%|██████████| 2292/2292 [11:38<00:00,  3.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [01:41<00:00,  3.73it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.618      0.191      0.188      0.102\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/40      19.1G      1.464      1.365      1.209        449        960: 100%|██████████| 2292/2292 [09:03<00:00,  4.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [01:47<00:00,  3.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.465       0.19      0.199       0.11\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/40      19.1G      1.493      1.267      1.227        484        960: 100%|██████████| 2292/2292 [08:54<00:00,  4.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [01:51<00:00,  3.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.469      0.185       0.19      0.107\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/40      19.1G      1.485      1.195      1.226        484        960: 100%|██████████| 2292/2292 [11:17<00:00,  3.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:44<00:00,  2.31it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.469      0.225      0.216      0.121\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/40      19.1G      1.435      1.111      1.199        644        960: 100%|██████████| 2292/2292 [12:55<00:00,  2.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [03:05<00:00,  2.04it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.396      0.252      0.239      0.134\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/40      19.1G      1.399      1.056      1.178        467        960: 100%|██████████| 2292/2292 [12:48<00:00,  2.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:35<00:00,  2.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.439      0.241      0.259      0.149\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/40      20.9G      1.378      1.024      1.164        483        960: 100%|██████████| 2292/2292 [12:46<00:00,  2.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:44<00:00,  2.31it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.395      0.274      0.263      0.152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/40      16.4G      1.359     0.9959      1.153        586        960: 100%|██████████| 2292/2292 [12:55<00:00,  2.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:51<00:00,  2.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.522       0.28      0.277      0.161\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/40      17.8G      1.342     0.9755      1.144        425        960: 100%|██████████| 2292/2292 [12:40<00:00,  3.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [03:08<00:00,  2.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.491      0.282      0.275      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/40      17.8G      1.328     0.9568      1.135        468        960: 100%|██████████| 2292/2292 [12:43<00:00,  3.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:45<00:00,  2.30it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.472      0.286      0.273      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/40      17.8G       1.32     0.9435      1.129        562        960: 100%|██████████| 2292/2292 [13:21<00:00,  2.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:45<00:00,  2.30it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.476      0.295      0.278      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/40      17.8G      1.308     0.9291      1.123        620        960: 100%|██████████| 2292/2292 [12:58<00:00,  2.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:50<00:00,  2.23it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.496      0.285       0.28      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/40      17.8G      1.302     0.9198      1.119        687        960: 100%|██████████| 2292/2292 [13:44<00:00,  2.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:40<00:00,  2.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.498      0.285      0.281      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/40      17.8G      1.291      0.909      1.113        475        960: 100%|██████████| 2292/2292 [13:15<00:00,  2.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:30<00:00,  2.52it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.494      0.287      0.282      0.161\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/40      17.8G      1.287      0.902      1.111        723        960: 100%|██████████| 2292/2292 [13:49<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:33<00:00,  2.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.504      0.287      0.283      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/40      17.8G      1.279     0.8915      1.106        565        960: 100%|██████████| 2292/2292 [12:48<00:00,  2.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:40<00:00,  2.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.517      0.281      0.283      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/40      17.8G       1.27     0.8817      1.101        517        960: 100%|██████████| 2292/2292 [12:54<00:00,  2.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:40<00:00,  2.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.507      0.286      0.282      0.161\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/40      17.8G      1.265     0.8736      1.098        578        960: 100%|██████████| 2292/2292 [12:58<00:00,  2.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:40<00:00,  2.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037       0.51      0.284      0.282      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/40      17.8G      1.259     0.8685      1.095        499        960: 100%|██████████| 2292/2292 [12:43<00:00,  3.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:51<00:00,  2.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037        0.5      0.287      0.283      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/40      17.8G      1.253     0.8614      1.091        419        960: 100%|██████████| 2292/2292 [12:32<00:00,  3.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:56<00:00,  2.15it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.497      0.288      0.283      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      21/40      17.8G      1.249     0.8558      1.089        688        960: 100%|██████████| 2292/2292 [12:56<00:00,  2.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:37<00:00,  2.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.503      0.286      0.284      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      22/40      19.6G      1.242     0.8471      1.086        470        960: 100%|██████████| 2292/2292 [13:04<00:00,  2.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:44<00:00,  2.31it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.515      0.284      0.285      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      23/40      19.6G      1.233     0.8387      1.082        515        960: 100%|██████████| 2292/2292 [12:55<00:00,  2.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:54<00:00,  2.17it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      21258     204037      0.518      0.285      0.287      0.164\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      24/40      19.6G       1.23      0.834      1.079        632        960: 100%|██████████| 2292/2292 [12:35<00:00,  3.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:46<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      21258     204037      0.518      0.285      0.287      0.165\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/40      19.6G      1.225     0.8282      1.077        655        960: 100%|██████████| 2292/2292 [12:38<00:00,  3.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:20<00:00,  2.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      21258     204037      0.504       0.29      0.288      0.165\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/40      19.6G      1.219     0.8218      1.074        531        960: 100%|██████████| 2292/2292 [12:37<00:00,  3.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:39<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      21258     204037      0.503      0.291      0.289      0.166\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/40      19.6G      1.211     0.8141       1.07        523        960: 100%|██████████| 2292/2292 [12:46<00:00,  2.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:47<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      21258     204037      0.506      0.292      0.289      0.167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/40      19.6G      1.207      0.808      1.067        543        960: 100%|██████████| 2292/2292 [12:28<00:00,  3.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:43<00:00,  2.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      21258     204037      0.502      0.295       0.29      0.167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/40      19.6G      1.203     0.8044      1.065        446        960: 100%|██████████| 2292/2292 [12:44<00:00,  3.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:48<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      21258     204037      0.503      0.296       0.29      0.169\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/40      19.6G      1.196     0.7972      1.061        463        960: 100%|██████████| 2292/2292 [12:49<00:00,  2.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 380/380 [02:34<00:00,  2.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      21258     204037      0.499      0.298      0.291      0.169\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/40      19.6G      1.221     0.7939       1.07        303        960:  14%|█▎        | 310/2292 [01:45<11:13,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-10-2918682439.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yolo11n.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myaml_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m960\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                     \u001b[0mloss_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                     pbar.set_description(\n\u001b[0m\u001b[1;32m    436\u001b[0m                         \u001b[0;34m(\u001b[0m\u001b[0;34m\"%11s\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"%11.4g\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                         % (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mset_description\u001b[0;34m(self, desc, refresh)\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \"\"\"\n\u001b[1;32m   1384\u001b[0m         \u001b[0mSet\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmodify\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprogress\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Resume training here\n",
        "model = YOLO(\"/content/runs/detect/train3/weights/last.pt\")\n",
        "start = time.time()\n",
        "model.train(resume=True,data=yaml_path, epochs=40, imgsz=960, batch=-1, patience=20)\n",
        "end = time.time()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VAxIupbStQpu",
        "outputId": "61c59a32-c30d-43cb-cf5a-06930ca1e2ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.170 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=bdd_dataset.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=40, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=960, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/runs/detect/train3/weights/last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=/content/runs/detect/train3/weights/last.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    433792  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n",
            "YOLO11n summary: 181 layers, 2,592,960 parameters, 2,592,944 gradients, 6.5 GFLOPs\n",
            "\n",
            "Transferred 499/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 560.6±767.3 ms, read: 0.2±0.2 MB/s, size: 365.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_yolov11n/labels/train... 6824 images, 322 backgrounds, 0 corrupt:  11%|█         | 7146/64177 [28:30<3:47:29,  4.18it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36mget_labels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"version\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDATASET_CACHE_VERSION\u001b[0m  \u001b[0;31m# matches current version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mget_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_files\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_files\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# identical hash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1710184624.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/runs/detect/train3/weights/last.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myaml_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m960\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mworld_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_ddp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# number of batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_setup_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# Batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# single-GPU only, estimate best batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# Dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/models/yolo/detect/train.py\u001b[0m in \u001b[0;36mauto_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \"\"\"\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moverride_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"cache\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0mmax_num_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cls\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m  \u001b[0;31m# 4 for mosaic augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mtrain_dataset\u001b[0m  \u001b[0;31m# free memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/models/yolo/detect/train.py\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(self, img_path, mode, batch)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"\"\"\n\u001b[1;32m     66\u001b[0m         \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_yolo_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36mbuild_yolo_dataset\u001b[0;34m(cfg, img_path, batch, data, mode, rect, stride, multi_modal)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;34m\"\"\"Build and return a YOLO dataset based on configuration parameters.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLOMultiModalDataset\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmulti_modal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mYOLODataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     return dataset(\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mimg_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, task, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_segments\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_keypoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Can not use both segments and keypoints.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"channels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcache_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./labels.cache\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, classes, fraction, channels)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_img_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# single_cls and include_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mni\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# number of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36mget_labels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mget_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_files\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_files\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# identical hash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# run cache ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# Display cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36mcache_labels\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    123\u001b[0m             )\n\u001b[1;32m    124\u001b[0m             \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTQDM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mim_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeypoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnm_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnf_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mne_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m                 \u001b[0mnm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnm_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mnf\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnf_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "metrics = model.val()\n",
        "print(\"\\n📊 Evaluation Results:\")\n",
        "print(f\"mAP@0.5:   {metrics.box.map50:.4f}\")\n",
        "# Use the correct attributes for precision, recall, and F1 score\n",
        "print(f\"Precision: {metrics.box.mp:.4f}\") # Access mp as an attribute\n",
        "print(f\"Recall:    {metrics.box.mr:.4f}\")  # Access mr as an attribute\n",
        "# Calculate mean F1 score if metrics.box.f1 is a list and not empty\n",
        "if isinstance(metrics.box.f1, list) and len(metrics.box.f1) > 0:\n",
        "    mean_f1 = sum(metrics.box.f1) / len(metrics.box.f1)\n",
        "    print(f\"F1 Score:  {mean_f1:.4f}\")\n",
        "else:\n",
        "    # Handle cases where f1 might not be a list or is empty\n",
        "    print(f\"F1 Score:  N/A\")\n",
        "\n",
        "\n",
        "print(f\"\\n⏱ Total Time: {timedelta(seconds=end - start)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "kgWXSiHLAX5-",
        "outputId": "c190f426-471c-431b-d187-56931bf90d46"
      },
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.170 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,585,272 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.3±0.0 ms, read: 0.3±0.1 MB/s, size: 228.9 KB)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_yolov11n/labels/test.cache... 20488 images, 770 backgrounds, 0 corrupt: 100%|██████████| 21258/21258 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_yolov11n/images/test/idd_highquality_16k_HYD-2018-08-24_13-22-50_0007776.jpg: 1 duplicate labels removed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1329/1329 [1:19:20<00:00,  3.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      21258     204037      0.496        0.3      0.291      0.169\n",
            "               bicycle       2169       3644      0.339      0.216      0.176     0.0561\n",
            "                   bus       2729       3351      0.402      0.347      0.316      0.214\n",
            "                   car      19804     145139      0.708      0.659      0.684      0.372\n",
            "            motorcycle       2143       4990       0.66      0.503      0.532      0.308\n",
            "          other person        193        290          1          0    0.00156   0.000685\n",
            "         other vehicle       1592       2248      0.471     0.0841      0.108     0.0562\n",
            "            pedestrian       7534      27000      0.477      0.313      0.322      0.132\n",
            "                 rider       2643       5303      0.621      0.381      0.426      0.236\n",
            "               trailer          1          1          0          0          0          0\n",
            "                 train         22         22          0          0          0          0\n",
            "                 truck       6828      10201      0.546      0.355      0.333        0.2\n",
            "                animal         67        223      0.525      0.229       0.28      0.135\n",
            "          autorickshaw        461       1019      0.721      0.672      0.716      0.523\n",
            "               caravan          5          6      0.317        0.5      0.187      0.158\n",
            "         traffic light         55        115      0.702      0.217      0.274      0.142\n",
            "          traffic sign        281        485      0.449      0.318        0.3      0.169\n",
            "Speed: 0.2ms preprocess, 1.0ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "\n",
            "📊 Evaluation Results:\n",
            "mAP@0.5:   0.2910\n",
            "Precision: 0.4962\n",
            "Recall:    0.2996\n",
            "F1 Score:  N/A\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'end' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3583985024.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n⏱ Total Time: {timedelta(seconds=end - start)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'end' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a reverse mapping from class ID to class name\n",
        "id_to_class_map = {idx: cls for cls, idx in class_map.items()}\n",
        "\n",
        "# Now you can access the class name using the integer ID\n",
        "class_name = id_to_class_map[1]\n",
        "print(class_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DtFYEyO_-k-",
        "outputId": "4ee83a6e-4053-4037-d596-c4c3b05d0183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uh1kv-PFSZVt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a8dd3e-3f55-4eb2-872b-5808d7055bf6",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 78.5ms\n",
            "Speed: 2.2ms preprocess, 78.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 23.3ms\n",
            "Speed: 2.8ms preprocess, 23.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.3ms\n",
            "Speed: 2.5ms preprocess, 16.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.2ms\n",
            "Speed: 2.7ms preprocess, 16.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 2.2ms preprocess, 13.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.3ms\n",
            "Speed: 2.3ms preprocess, 16.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 2.2ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.9ms\n",
            "Speed: 2.4ms preprocess, 17.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.4ms\n",
            "Speed: 2.4ms preprocess, 21.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.9ms\n",
            "Speed: 2.7ms preprocess, 17.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 2.5ms preprocess, 13.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.5ms\n",
            "Speed: 2.4ms preprocess, 17.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.8ms\n",
            "Speed: 2.5ms preprocess, 16.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 2.5ms preprocess, 17.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 3.9ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 29.5ms\n",
            "Speed: 2.3ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.6ms\n",
            "Speed: 2.6ms preprocess, 25.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 42.6ms\n",
            "Speed: 2.8ms preprocess, 42.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 23.0ms\n",
            "Speed: 7.5ms preprocess, 23.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.4ms\n",
            "Speed: 2.5ms preprocess, 15.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.1ms\n",
            "Speed: 3.0ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 2.3ms preprocess, 14.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 2.3ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.2ms\n",
            "Speed: 2.9ms preprocess, 18.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.9ms\n",
            "Speed: 5.1ms preprocess, 22.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 2.5ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.4ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 23.9ms\n",
            "Speed: 2.4ms preprocess, 23.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.6ms\n",
            "Speed: 2.2ms preprocess, 17.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 23.9ms\n",
            "Speed: 2.2ms preprocess, 23.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 4.1ms preprocess, 17.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.0ms\n",
            "Speed: 4.8ms preprocess, 20.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.0ms\n",
            "Speed: 2.5ms preprocess, 17.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.0ms\n",
            "Speed: 2.9ms preprocess, 14.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 2.4ms preprocess, 13.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.8ms\n",
            "Speed: 3.2ms preprocess, 16.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 23.3ms\n",
            "Speed: 2.3ms preprocess, 23.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.4ms\n",
            "Speed: 3.3ms preprocess, 25.4ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.4ms\n",
            "Speed: 3.5ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.3ms\n",
            "Speed: 3.9ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 27.8ms\n",
            "Speed: 4.7ms preprocess, 27.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.4ms\n",
            "Speed: 4.4ms preprocess, 20.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.6ms\n",
            "Speed: 10.6ms preprocess, 39.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 43.8ms\n",
            "Speed: 3.5ms preprocess, 43.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 33.2ms\n",
            "Speed: 2.3ms preprocess, 33.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.3ms\n",
            "Speed: 2.2ms preprocess, 39.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 26.6ms\n",
            "Speed: 2.4ms preprocess, 26.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 29.8ms\n",
            "Speed: 8.2ms preprocess, 29.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 38.0ms\n",
            "Speed: 2.1ms preprocess, 38.0ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.5ms\n",
            "Speed: 2.5ms preprocess, 18.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 26.4ms\n",
            "Speed: 2.2ms preprocess, 26.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 23.6ms\n",
            "Speed: 3.6ms preprocess, 23.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 3.7ms preprocess, 25.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 4.9ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.2ms\n",
            "Speed: 3.8ms preprocess, 18.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 29.0ms\n",
            "Speed: 4.9ms preprocess, 29.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.9ms\n",
            "Speed: 3.6ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 47.7ms\n",
            "Speed: 2.4ms preprocess, 47.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 30.6ms\n",
            "Speed: 15.5ms preprocess, 30.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.1ms\n",
            "Speed: 2.4ms preprocess, 39.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 3.1ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.8ms\n",
            "Speed: 4.1ms preprocess, 16.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.9ms\n",
            "Speed: 3.9ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.5ms\n",
            "Speed: 3.6ms preprocess, 15.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 34.3ms\n",
            "Speed: 2.4ms preprocess, 34.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 33.4ms\n",
            "Speed: 7.1ms preprocess, 33.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.3ms\n",
            "Speed: 4.4ms preprocess, 31.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.0ms\n",
            "Speed: 5.2ms preprocess, 25.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 29.4ms\n",
            "Speed: 2.5ms preprocess, 29.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 28.0ms\n",
            "Speed: 9.1ms preprocess, 28.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.0ms\n",
            "Speed: 8.2ms preprocess, 31.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 2.2ms preprocess, 15.8ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 36.2ms\n",
            "Speed: 2.3ms preprocess, 36.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 31.0ms\n",
            "Speed: 2.3ms preprocess, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 33.1ms\n",
            "Speed: 6.9ms preprocess, 33.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 37.0ms\n",
            "Speed: 4.2ms preprocess, 37.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.4ms\n",
            "Speed: 9.1ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 2.8ms preprocess, 17.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.9ms\n",
            "Speed: 3.2ms preprocess, 19.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.1ms\n",
            "Speed: 2.6ms preprocess, 18.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.6ms\n",
            "Speed: 3.5ms preprocess, 18.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.9ms\n",
            "Speed: 2.6ms preprocess, 17.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.8ms\n",
            "Speed: 2.8ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.7ms\n",
            "Speed: 2.8ms preprocess, 16.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.1ms\n",
            "Speed: 2.7ms preprocess, 25.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.1ms\n",
            "Speed: 2.2ms preprocess, 20.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 35.3ms\n",
            "Speed: 23.8ms preprocess, 35.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 34.9ms\n",
            "Speed: 2.2ms preprocess, 34.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 2.3ms preprocess, 17.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.2ms\n",
            "Speed: 2.4ms preprocess, 18.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 2.1ms preprocess, 14.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.4ms\n",
            "Speed: 2.2ms preprocess, 17.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.0ms\n",
            "Speed: 2.3ms preprocess, 17.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.5ms\n",
            "Speed: 2.2ms preprocess, 17.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 2.2ms preprocess, 17.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.7ms\n",
            "Speed: 2.6ms preprocess, 21.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.8ms\n",
            "Speed: 2.6ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 2.9ms preprocess, 17.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 3.0ms preprocess, 17.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.0ms\n",
            "Speed: 4.0ms preprocess, 18.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 2.9ms preprocess, 17.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 2.8ms preprocess, 17.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.3ms\n",
            "Speed: 2.8ms preprocess, 19.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.5ms\n",
            "Speed: 2.3ms preprocess, 17.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 46.2ms\n",
            "Speed: 6.2ms preprocess, 46.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.1ms\n",
            "Speed: 4.3ms preprocess, 18.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.1ms\n",
            "Speed: 2.6ms preprocess, 16.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 3.7ms preprocess, 17.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 2.2ms preprocess, 14.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.5ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.5ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.3ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 2.2ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 2.5ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 3.7ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 2.4ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.4ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.6ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 2.8ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 52.7ms\n",
            "Speed: 2.4ms preprocess, 52.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.6ms\n",
            "Speed: 2.5ms preprocess, 19.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.4ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 9.2ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 2.5ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.8ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 4.4ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.2ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.2ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 1.6ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 2.1ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 3.3ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.5ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.5ms\n",
            "Speed: 2.6ms preprocess, 15.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 4.4ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 1.7ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 2.9ms preprocess, 9.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 2.5ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.5ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.8ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.6ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 3.8ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 1.7ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 2.2ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 2.5ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.1ms\n",
            "Speed: 2.3ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 54.2ms\n",
            "Speed: 2.2ms preprocess, 54.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 2.0ms preprocess, 13.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.7ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.6ms\n",
            "Speed: 4.0ms preprocess, 18.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.6ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 3.3ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.6ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 2.5ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 2.8ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.6ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 2.1ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.7ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.2ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 2.2ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 2.5ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 2.0ms preprocess, 8.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.5ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.2ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.4ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.2ms\n",
            "Speed: 6.0ms preprocess, 15.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.3ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 2.3ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.3ms\n",
            "Speed: 2.4ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.2ms\n",
            "Speed: 2.6ms preprocess, 16.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.9ms\n",
            "Speed: 2.3ms preprocess, 14.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 3.7ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 1.7ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.5ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 2.4ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.3ms\n",
            "Speed: 2.5ms preprocess, 18.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 2.9ms preprocess, 13.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.0ms\n",
            "Speed: 2.1ms preprocess, 19.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.0ms\n",
            "Speed: 2.4ms preprocess, 18.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.7ms\n",
            "Speed: 2.8ms preprocess, 18.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.9ms\n",
            "Speed: 2.8ms preprocess, 18.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.1ms\n",
            "Speed: 2.4ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 2.5ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.7ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 2.5ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.4ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.6ms\n",
            "Speed: 2.9ms preprocess, 17.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 3.3ms preprocess, 13.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.3ms\n",
            "Speed: 2.3ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 3.2ms preprocess, 16.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 2.5ms preprocess, 16.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 2.3ms preprocess, 17.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 2.4ms preprocess, 17.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.8ms\n",
            "Speed: 3.9ms preprocess, 17.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.8ms\n",
            "Speed: 2.3ms preprocess, 17.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.8ms\n",
            "Speed: 2.3ms preprocess, 17.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 2.2ms preprocess, 16.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.4ms\n",
            "Speed: 2.4ms preprocess, 16.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 2.5ms preprocess, 17.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 2.4ms preprocess, 17.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.6ms\n",
            "Speed: 2.3ms preprocess, 17.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.5ms\n",
            "Speed: 2.5ms preprocess, 17.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.8ms\n",
            "Speed: 2.4ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.6ms\n",
            "Speed: 2.5ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 34.9ms\n",
            "Speed: 4.1ms preprocess, 34.9ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.0ms\n",
            "Speed: 2.4ms preprocess, 20.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 26.2ms\n",
            "Speed: 3.0ms preprocess, 26.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.7ms\n",
            "Speed: 2.9ms preprocess, 18.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 26.8ms\n",
            "Speed: 2.9ms preprocess, 26.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.1ms\n",
            "Speed: 2.8ms preprocess, 20.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.4ms\n",
            "Speed: 2.5ms preprocess, 19.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 2.4ms preprocess, 17.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.1ms\n",
            "Speed: 2.5ms preprocess, 14.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.9ms\n",
            "Speed: 2.7ms preprocess, 16.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.3ms\n",
            "Speed: 2.6ms preprocess, 18.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.8ms\n",
            "Speed: 2.5ms preprocess, 16.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.5ms\n",
            "Speed: 2.6ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.1ms\n",
            "Speed: 2.6ms preprocess, 17.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 2.7ms preprocess, 17.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.7ms\n",
            "Speed: 2.9ms preprocess, 19.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.7ms\n",
            "Speed: 2.9ms preprocess, 18.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.6ms\n",
            "Speed: 2.5ms preprocess, 17.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 2.3ms preprocess, 17.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.1ms\n",
            "Speed: 10.5ms preprocess, 21.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.5ms\n",
            "Speed: 3.9ms preprocess, 20.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 137.3ms\n",
            "Speed: 4.9ms preprocess, 137.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 215.0ms\n",
            "Speed: 74.0ms preprocess, 215.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 2.3ms preprocess, 17.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.3ms\n",
            "Speed: 2.2ms preprocess, 14.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.9ms\n",
            "Speed: 4.0ms preprocess, 16.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 2.2ms preprocess, 16.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.1ms\n",
            "Speed: 2.7ms preprocess, 17.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 2.2ms preprocess, 16.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.5ms\n",
            "Speed: 2.3ms preprocess, 16.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.5ms\n",
            "Speed: 2.3ms preprocess, 17.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.9ms\n",
            "Speed: 3.8ms preprocess, 16.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 5.4ms preprocess, 17.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.0ms\n",
            "Speed: 10.0ms preprocess, 17.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 4.3ms preprocess, 16.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 44.4ms\n",
            "Speed: 6.2ms preprocess, 44.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.9ms\n",
            "Speed: 2.6ms preprocess, 16.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.2ms\n",
            "Speed: 3.3ms preprocess, 18.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.5ms\n",
            "Speed: 2.6ms preprocess, 18.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 33.9ms\n",
            "Speed: 3.1ms preprocess, 33.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.0ms\n",
            "Speed: 3.3ms preprocess, 18.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 28.5ms\n",
            "Speed: 3.3ms preprocess, 28.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.1ms\n",
            "Speed: 3.1ms preprocess, 17.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 36.0ms\n",
            "Speed: 2.8ms preprocess, 36.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 26.0ms\n",
            "Speed: 3.0ms preprocess, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 33.9ms\n",
            "Speed: 2.1ms preprocess, 33.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 29.2ms\n",
            "Speed: 2.2ms preprocess, 29.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.1ms\n",
            "Speed: 2.5ms preprocess, 22.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 27.2ms\n",
            "Speed: 4.4ms preprocess, 27.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 4.5ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.2ms\n",
            "Speed: 2.4ms preprocess, 21.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.1ms\n",
            "Speed: 2.4ms preprocess, 19.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.9ms\n",
            "Speed: 2.3ms preprocess, 15.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.2ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.0ms\n",
            "Speed: 2.3ms preprocess, 17.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 2.4ms preprocess, 17.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 2.2ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 2.6ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.9ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.2ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.4ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.2ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.3ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.0ms\n",
            "Speed: 2.3ms preprocess, 18.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.0ms\n",
            "Speed: 2.2ms preprocess, 16.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.9ms\n",
            "Speed: 4.4ms preprocess, 15.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.4ms\n",
            "Speed: 2.3ms preprocess, 17.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 2.7ms preprocess, 15.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.0ms\n",
            "Speed: 2.1ms preprocess, 18.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.1ms\n",
            "Speed: 2.4ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.4ms\n",
            "Speed: 2.1ms preprocess, 17.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.1ms\n",
            "Speed: 2.3ms preprocess, 18.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.1ms\n",
            "Speed: 2.1ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.4ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.6ms\n",
            "Speed: 2.2ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 2.4ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.2ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 2.3ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 2.2ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.6ms\n",
            "Speed: 4.4ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.3ms\n",
            "Speed: 3.2ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 2.6ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 2.2ms preprocess, 16.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.1ms\n",
            "Speed: 2.5ms preprocess, 14.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 2.2ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.2ms\n",
            "Speed: 2.4ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.4ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 2.1ms preprocess, 15.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.7ms\n",
            "Speed: 3.3ms preprocess, 15.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.0ms\n",
            "Speed: 2.5ms preprocess, 16.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 2.3ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 2.4ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 2.3ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 3.4ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 2.2ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.4ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.5ms\n",
            "Speed: 4.0ms preprocess, 18.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.8ms\n",
            "Speed: 2.3ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.4ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.4ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.4ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 2.4ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 3.6ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.0ms\n",
            "Speed: 2.4ms preprocess, 17.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.6ms\n",
            "Speed: 2.5ms preprocess, 15.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 26.2ms\n",
            "Speed: 6.2ms preprocess, 26.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 46.3ms\n",
            "Speed: 3.3ms preprocess, 46.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 3.3ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.9ms\n",
            "Speed: 2.2ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.9ms\n",
            "Speed: 2.2ms preprocess, 16.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.3ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 4.2ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.8ms\n",
            "Speed: 2.3ms preprocess, 16.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.6ms\n",
            "Speed: 3.3ms preprocess, 17.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.8ms\n",
            "Speed: 2.2ms preprocess, 16.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 2.4ms preprocess, 17.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.3ms\n",
            "Speed: 2.3ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.6ms\n",
            "Speed: 2.2ms preprocess, 15.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.1ms\n",
            "Speed: 2.2ms preprocess, 22.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 5.4ms preprocess, 17.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 2.3ms preprocess, 17.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.9ms\n",
            "Speed: 2.8ms preprocess, 15.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.0ms\n",
            "Speed: 2.6ms preprocess, 25.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.5ms\n",
            "Speed: 2.2ms preprocess, 18.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 47.7ms\n",
            "Speed: 15.2ms preprocess, 47.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.0ms\n",
            "Speed: 2.2ms preprocess, 14.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.4ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 2.3ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.6ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 1.7ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.5ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 2.5ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.4ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 4.2ms preprocess, 8.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 2.5ms preprocess, 8.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 2.2ms preprocess, 16.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 2.6ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 2.6ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 2.7ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.9ms\n",
            "Speed: 2.7ms preprocess, 16.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 2.7ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.9ms\n",
            "Speed: 2.2ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 1.7ms preprocess, 9.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 2.5ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 7.0ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.3ms\n",
            "Speed: 2.4ms preprocess, 18.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 34.4ms\n",
            "Speed: 2.6ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.4ms\n",
            "Speed: 2.4ms preprocess, 16.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.9ms\n",
            "Speed: 2.9ms preprocess, 17.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.5ms\n",
            "Speed: 2.8ms preprocess, 18.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 5.5ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 4.9ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.6ms\n",
            "Speed: 2.7ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 2.2ms preprocess, 12.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.0ms\n",
            "Speed: 2.4ms preprocess, 18.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.5ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.3ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 2.6ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.5ms\n",
            "Speed: 2.9ms preprocess, 16.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.1ms\n",
            "Speed: 2.4ms preprocess, 15.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.6ms\n",
            "Speed: 2.6ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 2.7ms preprocess, 16.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 2.7ms preprocess, 17.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.4ms\n",
            "Speed: 2.7ms preprocess, 22.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.1ms\n",
            "Speed: 2.4ms preprocess, 25.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.8ms\n",
            "Speed: 2.6ms preprocess, 16.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.9ms\n",
            "Speed: 2.1ms preprocess, 17.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.8ms\n",
            "Speed: 2.5ms preprocess, 21.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.2ms\n",
            "Speed: 2.3ms preprocess, 18.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.1ms\n",
            "Speed: 2.4ms preprocess, 18.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 6.3ms preprocess, 17.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 2.3ms preprocess, 17.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.4ms\n",
            "Speed: 2.9ms preprocess, 17.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.4ms\n",
            "Speed: 2.2ms preprocess, 17.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.4ms\n",
            "Speed: 2.5ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 34.9ms\n",
            "Speed: 2.2ms preprocess, 34.9ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.8ms\n",
            "Speed: 2.3ms preprocess, 22.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.0ms\n",
            "Speed: 2.6ms preprocess, 18.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 2.4ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 2.4ms preprocess, 17.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.0ms\n",
            "Speed: 2.4ms preprocess, 18.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.4ms\n",
            "Speed: 2.9ms preprocess, 18.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.8ms\n",
            "Speed: 2.9ms preprocess, 17.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.2ms\n",
            "Speed: 3.1ms preprocess, 16.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 33.6ms\n",
            "Speed: 2.3ms preprocess, 33.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.2ms\n",
            "Speed: 2.3ms preprocess, 18.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.1ms\n",
            "Speed: 2.4ms preprocess, 21.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 23.5ms\n",
            "Speed: 2.4ms preprocess, 23.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.5ms\n",
            "Speed: 3.2ms preprocess, 17.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 3.1ms preprocess, 17.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 2.4ms preprocess, 17.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.6ms\n",
            "Speed: 2.6ms preprocess, 20.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.4ms\n",
            "Speed: 4.4ms preprocess, 18.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.5ms\n",
            "Speed: 3.3ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.2ms\n",
            "Speed: 3.4ms preprocess, 18.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.8ms\n",
            "Speed: 3.2ms preprocess, 25.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.2ms\n",
            "Speed: 3.0ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 24.2ms\n",
            "Speed: 2.9ms preprocess, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.0ms\n",
            "Speed: 3.1ms preprocess, 18.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 2.8ms preprocess, 17.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 3.2ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.0ms\n",
            "Speed: 2.9ms preprocess, 18.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.1ms\n",
            "Speed: 2.9ms preprocess, 18.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.0ms\n",
            "Speed: 2.8ms preprocess, 19.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.5ms\n",
            "Speed: 2.3ms preprocess, 17.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 36.1ms\n",
            "Speed: 2.4ms preprocess, 36.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 3.3ms preprocess, 14.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.9ms\n",
            "Speed: 2.8ms preprocess, 16.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.8ms\n",
            "Speed: 4.2ms preprocess, 16.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.8ms\n",
            "Speed: 2.3ms preprocess, 16.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.8ms\n",
            "Speed: 2.2ms preprocess, 16.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.3ms\n",
            "Speed: 2.3ms preprocess, 18.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.9ms\n",
            "Speed: 2.4ms preprocess, 16.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.1ms\n",
            "Speed: 2.3ms preprocess, 17.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.4ms\n",
            "Speed: 2.2ms preprocess, 17.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 2.4ms preprocess, 16.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.6ms\n",
            "Speed: 2.6ms preprocess, 20.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.9ms\n",
            "Speed: 2.9ms preprocess, 18.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.3ms\n",
            "Speed: 2.5ms preprocess, 18.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.0ms\n",
            "Speed: 2.5ms preprocess, 18.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.4ms\n",
            "Speed: 3.1ms preprocess, 17.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.1ms\n",
            "Speed: 2.9ms preprocess, 18.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 36.8ms\n",
            "Speed: 2.3ms preprocess, 36.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 45.8ms\n",
            "Speed: 2.3ms preprocess, 45.8ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.6ms\n",
            "Speed: 4.2ms preprocess, 18.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.5ms preprocess, 9.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.4ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 2.2ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.7ms\n",
            "Speed: 2.4ms preprocess, 14.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.4ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 3.0ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.6ms\n",
            "Speed: 3.5ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.4ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.6ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 4.6ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.4ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.7ms\n",
            "Speed: 6.6ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.0ms\n",
            "Speed: 2.7ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.6ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.1ms\n",
            "Speed: 2.4ms preprocess, 18.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.0ms\n",
            "Speed: 2.3ms preprocess, 14.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.5ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 2.4ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 33.2ms\n",
            "Speed: 2.3ms preprocess, 33.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.6ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 2.5ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 2.3ms preprocess, 14.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 2.6ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.4ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.9ms\n",
            "Speed: 3.1ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 2.4ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.4ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.7ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 3.8ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.4ms preprocess, 9.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 2.2ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 2.5ms preprocess, 14.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 2.4ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.5ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.8ms\n",
            "Speed: 2.5ms preprocess, 14.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 2.3ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 3.0ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.4ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 3.9ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.7ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.5ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.6ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 2.9ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.3ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.3ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 2.5ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.9ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.4ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 3.7ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.6ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 2.3ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 2.4ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.6ms\n",
            "Speed: 5.0ms preprocess, 15.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.1ms\n",
            "Speed: 2.8ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 2.6ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 2.7ms preprocess, 17.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 52.4ms\n",
            "Speed: 2.2ms preprocess, 52.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 2.7ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.9ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.6ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.3ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.5ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 2.6ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.6ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 2.7ms preprocess, 13.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 3.3ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 2.3ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.8ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.4ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.6ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 3.0ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 3.5ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.6ms\n",
            "Speed: 1.8ms preprocess, 15.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.2ms\n",
            "Speed: 2.4ms preprocess, 15.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 2.7ms preprocess, 15.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.7ms\n",
            "Speed: 3.5ms preprocess, 16.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.9ms\n",
            "Speed: 2.8ms preprocess, 20.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 56.4ms\n",
            "Speed: 6.8ms preprocess, 56.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 28.5ms\n",
            "Speed: 2.3ms preprocess, 28.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 2.3ms preprocess, 17.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.2ms\n",
            "Speed: 2.5ms preprocess, 21.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 2.2ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.1ms\n",
            "Speed: 2.7ms preprocess, 14.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 2.2ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.4ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 2.3ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.4ms\n",
            "Speed: 2.1ms preprocess, 14.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.5ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.9ms\n",
            "Speed: 2.5ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 2.3ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.4ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.4ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.0ms\n",
            "Speed: 2.2ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.9ms\n",
            "Speed: 2.3ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.4ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 2.4ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.5ms\n",
            "Speed: 2.4ms preprocess, 17.5ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.1ms\n",
            "Speed: 2.8ms preprocess, 19.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 27.7ms\n",
            "Speed: 2.2ms preprocess, 27.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 23.7ms\n",
            "Speed: 2.2ms preprocess, 23.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.5ms\n",
            "Speed: 2.6ms preprocess, 18.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.3ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 3.3ms preprocess, 13.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 2.5ms preprocess, 13.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 2.4ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 23.6ms\n",
            "Speed: 3.2ms preprocess, 23.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.4ms\n",
            "Speed: 2.4ms preprocess, 19.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.3ms\n",
            "Speed: 3.4ms preprocess, 22.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.1ms\n",
            "Speed: 2.3ms preprocess, 19.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.3ms\n",
            "Speed: 2.3ms preprocess, 19.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.8ms\n",
            "Speed: 2.3ms preprocess, 19.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 2.2ms preprocess, 17.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.7ms\n",
            "Speed: 2.3ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.1ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 2.2ms preprocess, 13.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 2.3ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 2.2ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 5.5ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.8ms\n",
            "Speed: 6.5ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.2ms\n",
            "Speed: 2.2ms preprocess, 15.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.9ms\n",
            "Speed: 2.3ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.3ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.4ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 2.3ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.4ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.4ms\n",
            "Speed: 2.2ms preprocess, 13.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.3ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.3ms\n",
            "Speed: 2.1ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 23.3ms\n",
            "Speed: 12.1ms preprocess, 23.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.3ms\n",
            "Speed: 2.4ms preprocess, 19.3ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 2.3ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 2.3ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.9ms\n",
            "Speed: 2.3ms preprocess, 14.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 2.4ms preprocess, 17.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.3ms\n",
            "Speed: 2.3ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 3.2ms preprocess, 16.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.8ms\n",
            "Speed: 3.5ms preprocess, 14.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.6ms\n",
            "Speed: 4.5ms preprocess, 18.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.2ms\n",
            "Speed: 4.4ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 3.0ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.3ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 2.4ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.0ms\n",
            "Speed: 2.3ms preprocess, 21.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.8ms\n",
            "Speed: 2.5ms preprocess, 19.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 35.5ms\n",
            "Speed: 2.3ms preprocess, 35.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 44.2ms\n",
            "Speed: 2.4ms preprocess, 44.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.3ms\n",
            "Speed: 2.2ms preprocess, 16.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.4ms\n",
            "Speed: 2.3ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.0ms\n",
            "Speed: 2.4ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.2ms\n",
            "Speed: 2.2ms preprocess, 15.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.2ms\n",
            "Speed: 2.2ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 2.3ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 2.1ms preprocess, 13.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.2ms\n",
            "Speed: 2.5ms preprocess, 21.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.5ms\n",
            "Speed: 2.6ms preprocess, 18.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.6ms\n",
            "Speed: 2.3ms preprocess, 17.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 2.5ms preprocess, 13.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.6ms\n",
            "Speed: 2.5ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 24.5ms\n",
            "Speed: 2.3ms preprocess, 24.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 2.5ms preprocess, 16.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.4ms\n",
            "Speed: 2.2ms preprocess, 16.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 23.8ms\n",
            "Speed: 2.8ms preprocess, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.3ms\n",
            "Speed: 2.3ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.3ms\n",
            "Speed: 2.3ms preprocess, 18.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 45.8ms\n",
            "Speed: 2.4ms preprocess, 45.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.9ms\n",
            "Speed: 2.3ms preprocess, 17.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.5ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 2.3ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 3.7ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 2.3ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 2.2ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 2.5ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 2.4ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.4ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 3.2ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.4ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.9ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 2.4ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.3ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.6ms\n",
            "Speed: 2.5ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 2.3ms preprocess, 14.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.4ms\n",
            "Speed: 2.7ms preprocess, 16.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 52.3ms\n",
            "Speed: 2.2ms preprocess, 52.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 2.2ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 2.4ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.3ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.3ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 5.7ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.9ms\n",
            "Speed: 2.2ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.9ms\n",
            "Speed: 2.6ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.6ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 2.6ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.5ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.9ms\n",
            "Speed: 2.3ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 1.7ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 2.3ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.3ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 4.4ms preprocess, 14.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.3ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.9ms\n",
            "Speed: 2.2ms preprocess, 13.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 2.5ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 2.8ms preprocess, 8.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.4ms\n",
            "Speed: 2.1ms preprocess, 13.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.3ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.2ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 3.5ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.4ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.3ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 1.7ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.5ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 2.5ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.1ms\n",
            "Speed: 2.4ms preprocess, 22.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.6ms\n",
            "Speed: 3.2ms preprocess, 18.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 2.7ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 2.5ms preprocess, 13.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 3.2ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.9ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 53.5ms\n",
            "Speed: 2.2ms preprocess, 53.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 4.5ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.4ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.3ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 2.3ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.7ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.6ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.5ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 2.3ms preprocess, 14.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.8ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.9ms\n",
            "Speed: 8.6ms preprocess, 15.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.4ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 2.6ms preprocess, 13.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 2.8ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 2.6ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.5ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.5ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.0ms\n",
            "Speed: 2.8ms preprocess, 14.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 2.5ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.5ms\n",
            "Speed: 2.5ms preprocess, 16.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.6ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.6ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.5ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.4ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 3.0ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 2.7ms preprocess, 14.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 2.3ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.3ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 2.4ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.3ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.6ms\n",
            "Speed: 2.2ms preprocess, 20.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.9ms\n",
            "Speed: 2.3ms preprocess, 16.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.4ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 2.2ms preprocess, 12.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 3.6ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 2.4ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 2.2ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.3ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 2.3ms preprocess, 14.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.3ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 2.3ms preprocess, 12.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 2.5ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 2.4ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.5ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.3ms\n",
            "Speed: 2.3ms preprocess, 14.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.6ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.5ms preprocess, 12.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 55.4ms\n",
            "Speed: 2.3ms preprocess, 55.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.0ms\n",
            "Speed: 2.3ms preprocess, 22.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.7ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 3.3ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.1ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 42.6ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.4ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 2.6ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 2.4ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.6ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.2ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 2.4ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.3ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.3ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.7ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.8ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.8ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 2.6ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 2.4ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.3ms\n",
            "Speed: 2.4ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.9ms\n",
            "Speed: 2.2ms preprocess, 21.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.2ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 2.3ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 49.7ms\n",
            "Speed: 1.8ms preprocess, 49.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 5.5ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 2.2ms preprocess, 13.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 2.4ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.2ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.0ms\n",
            "Speed: 2.4ms preprocess, 14.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.9ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 2.5ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.3ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.6ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.4ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.5ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.4ms\n",
            "Speed: 2.2ms preprocess, 21.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 2.5ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 3.5ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 2.4ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.6ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 2.4ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.4ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.3ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.0ms\n",
            "Speed: 3.7ms preprocess, 14.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.2ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.4ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.6ms\n",
            "Speed: 3.5ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 2.6ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 2.6ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.8ms\n",
            "Speed: 2.7ms preprocess, 14.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.3ms\n",
            "Speed: 2.3ms preprocess, 18.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.9ms\n",
            "Speed: 2.2ms preprocess, 19.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.5ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.1ms\n",
            "Speed: 2.2ms preprocess, 15.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 2.5ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 5.2ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 2.2ms preprocess, 12.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 5.2ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 2.3ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 2.2ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.3ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 2.3ms preprocess, 13.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.0ms\n",
            "Speed: 2.4ms preprocess, 14.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 3.9ms preprocess, 9.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.6ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.4ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.9ms\n",
            "Speed: 2.3ms preprocess, 18.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.1ms\n",
            "Speed: 3.2ms preprocess, 16.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.0ms\n",
            "Speed: 5.0ms preprocess, 19.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 33.5ms\n",
            "Speed: 2.7ms preprocess, 33.5ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.7ms\n",
            "Speed: 4.8ms preprocess, 19.7ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 6.3ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.4ms\n",
            "Speed: 6.1ms preprocess, 17.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.9ms\n",
            "Speed: 2.8ms preprocess, 19.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 2.2ms preprocess, 15.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 3.2ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.3ms\n",
            "Speed: 4.7ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.2ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.1ms\n",
            "Speed: 2.3ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.1ms\n",
            "Speed: 2.2ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.7ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 2.3ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 2.2ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.6ms\n",
            "Speed: 2.5ms preprocess, 15.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.0ms\n",
            "Speed: 2.4ms preprocess, 16.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.3ms\n",
            "Speed: 2.3ms preprocess, 15.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 2.4ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 2.3ms preprocess, 13.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.3ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.3ms\n",
            "Speed: 2.3ms preprocess, 22.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 2.7ms preprocess, 11.9ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.9ms\n",
            "Speed: 3.2ms preprocess, 19.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.2ms\n",
            "Speed: 2.3ms preprocess, 15.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.0ms\n",
            "Speed: 2.3ms preprocess, 15.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.4ms\n",
            "Speed: 2.1ms preprocess, 13.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 2.2ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.4ms\n",
            "Speed: 2.9ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.3ms\n",
            "Speed: 2.4ms preprocess, 18.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 4.5ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.9ms\n",
            "Speed: 2.2ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.9ms\n",
            "Speed: 2.3ms preprocess, 18.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 2.5ms preprocess, 13.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.3ms\n",
            "Speed: 5.3ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 5.5ms preprocess, 17.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 2.5ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 28.1ms\n",
            "Speed: 2.6ms preprocess, 28.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 36.1ms\n",
            "Speed: 2.2ms preprocess, 36.1ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.1ms\n",
            "Speed: 2.4ms preprocess, 19.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 53.8ms\n",
            "Speed: 8.1ms preprocess, 53.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.6ms\n",
            "Speed: 8.3ms preprocess, 21.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 74.4ms\n",
            "Speed: 6.4ms preprocess, 74.4ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 34.9ms\n",
            "Speed: 2.4ms preprocess, 34.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 69.7ms\n",
            "Speed: 5.8ms preprocess, 69.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 153.4ms\n",
            "Speed: 14.3ms preprocess, 153.4ms inference, 31.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 27.4ms\n",
            "Speed: 2.2ms preprocess, 27.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 7.0ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.0ms\n",
            "Speed: 2.3ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 2.1ms preprocess, 15.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 2.1ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.1ms\n",
            "Speed: 6.7ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.7ms\n",
            "Speed: 2.5ms preprocess, 16.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.7ms\n",
            "Speed: 2.4ms preprocess, 19.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.3ms\n",
            "Speed: 2.1ms preprocess, 20.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 2.3ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 3.0ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.4ms\n",
            "Speed: 2.2ms preprocess, 15.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 2.2ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.3ms\n",
            "Speed: 2.1ms preprocess, 15.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 29.1ms\n",
            "Speed: 2.2ms preprocess, 29.1ms inference, 9.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 36.4ms\n",
            "Speed: 2.2ms preprocess, 36.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.4ms\n",
            "Speed: 2.1ms preprocess, 13.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 2.1ms preprocess, 17.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 6.6ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.3ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 2.9ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.6ms\n",
            "Speed: 3.3ms preprocess, 18.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.5ms\n",
            "Speed: 2.4ms preprocess, 19.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.4ms\n",
            "Speed: 2.3ms preprocess, 16.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.4ms\n",
            "Speed: 2.7ms preprocess, 15.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.1ms\n",
            "Speed: 2.3ms preprocess, 16.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.5ms\n",
            "Speed: 2.3ms preprocess, 17.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.9ms\n",
            "Speed: 2.4ms preprocess, 17.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.1ms\n",
            "Speed: 4.4ms preprocess, 17.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 24.7ms\n",
            "Speed: 2.2ms preprocess, 24.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.4ms\n",
            "Speed: 2.2ms preprocess, 18.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 5.9ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.6ms\n",
            "Speed: 2.4ms preprocess, 17.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.5ms\n",
            "Speed: 2.2ms preprocess, 20.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.1ms\n",
            "Speed: 3.6ms preprocess, 21.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 45.0ms\n",
            "Speed: 3.2ms preprocess, 45.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 40.2ms\n",
            "Speed: 2.2ms preprocess, 40.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 2.3ms preprocess, 17.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.8ms\n",
            "Speed: 2.3ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.5ms\n",
            "Speed: 2.5ms preprocess, 15.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.6ms\n",
            "Speed: 2.1ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.9ms\n",
            "Speed: 2.3ms preprocess, 20.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 27.4ms\n",
            "Speed: 2.6ms preprocess, 27.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.0ms\n",
            "Speed: 2.4ms preprocess, 20.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.9ms\n",
            "Speed: 3.1ms preprocess, 18.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.0ms\n",
            "Speed: 2.4ms preprocess, 19.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.8ms\n",
            "Speed: 5.2ms preprocess, 16.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.6ms\n",
            "Speed: 3.3ms preprocess, 21.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 2.6ms preprocess, 14.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.6ms\n",
            "Speed: 2.6ms preprocess, 17.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 24.8ms\n",
            "Speed: 2.5ms preprocess, 24.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 2.8ms preprocess, 14.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.5ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 43.2ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 4.6ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 2.4ms preprocess, 14.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.4ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.4ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.8ms\n",
            "Speed: 2.2ms preprocess, 14.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.3ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.7ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 2.4ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 3.1ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 2.4ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 2.5ms preprocess, 13.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 2.2ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.4ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 2.5ms preprocess, 13.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.4ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 2.4ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "✅ Annotated video saved to: annotated_output.mp4\n"
          ]
        }
      ],
      "source": [
        "# 🔧 Configuration\n",
        "video_path = '/content/drive/MyDrive/driving-video-with-object-tracking/bdd100k_videos_train_00/bdd100k/videos/train/01a8723d-89a1953a.mov'  # Input video file (can be .mov or .mp4)\n",
        "output_path = 'annotated_output.mp4'  # Output video file\n",
        "\n",
        "# 🎨 Class-specific colors for bounding boxes\n",
        "CLASS_COLORS = {\n",
        "    'bicycle': (0, 191, 255),        # Electric Blue – easily visible and distinct\n",
        "    'bus': (255, 85, 0),             # Fire Orange – high contrast for large vehicles\n",
        "    'car': (0, 255, 127),            # Spring Green – soft but stands out on urban roads\n",
        "    'motorcycle': (255, 105, 180),   # Hot Pink – vivid for fast-moving bikes\n",
        "    'other person': (204, 204, 0),   # Mustard Yellow – clear visibility for ambiguous figures\n",
        "    'other vehicle': (128, 128, 128),# Gray – neutral for unclassified vehicle types\n",
        "    'pedestrian': (50, 205, 50),     # Lime Green – associated with people and movement\n",
        "    'rider': (186, 85, 211),         # Medium Orchid – bold and eye-catching for bike riders\n",
        "    'trailer': (210, 105, 30),       # Chocolate – earthy tone for large towed units\n",
        "    'train': (0, 0, 139),            # Dark Blue – fits the profile of rail-bound objects\n",
        "    'truck': (218, 165, 32),         # Goldenrod – strong presence for heavy-duty vehicles\n",
        "}\n",
        "\n",
        "# 🎞️ Open input video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "# 🔁 Process frames\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 🔍 Run inference on the current frame\n",
        "    results = model.predict(frame, save=False)[0]\n",
        "\n",
        "    # 🎨 Annotate each detected object with a class-specific color\n",
        "    for box in results.boxes:\n",
        "        cls_id = int(box.cls)\n",
        "        conf = float(box.conf)\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "        cls_name = id_to_class_map[cls_id]\n",
        "        color = CLASS_COLORS.get(cls_name, (255, 255, 255))  # Default to white if undefined\n",
        "\n",
        "        # 🖼️ Draw the bounding box and label\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "        label = f\"{cls_name} {conf:.2f}\"\n",
        "        cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "\n",
        "    # 💾 Write the annotated frame to the output video\n",
        "    out.write(frame)\n",
        "\n",
        "# 🧹 Release video objects\n",
        "cap.release()\n",
        "out.release()\n",
        "print(f\"✅ Annotated video saved to: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download runs folder to /content/drive/MyDrive/driving-video-with-object-tracking\n",
        "\n",
        "!tar -czvf /tmp/runs_July31.tar.gz runs\n",
        "!cp /tmp/runs_July31.tar.gz /content/drive/MyDrive/driving-video-with-object-tracking/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sz23oHkCBiCz",
        "outputId": "5d98dbfb-4e67-4f31-9686-8988345b3dea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "runs/\n",
            "runs/detect/\n",
            "runs/detect/train2/\n",
            "runs/detect/train2/labels_correlogram.jpg\n",
            "runs/detect/train2/train_batch0.jpg\n",
            "runs/detect/train2/weights/\n",
            "runs/detect/train2/weights/last.pt\n",
            "runs/detect/train2/weights/best.pt\n",
            "runs/detect/train2/train_batch2.jpg\n",
            "runs/detect/train2/train_batch1.jpg\n",
            "runs/detect/train2/args.yaml\n",
            "runs/detect/train2/results.csv\n",
            "runs/detect/train2/labels.jpg\n",
            "runs/detect/train3/\n",
            "runs/detect/train3/labels_correlogram.jpg\n",
            "runs/detect/train3/train_batch0.jpg\n",
            "runs/detect/train3/weights/\n",
            "runs/detect/train3/weights/last.pt\n",
            "runs/detect/train3/weights/best.pt\n",
            "runs/detect/train3/train_batch68760.jpg\n",
            "runs/detect/train3/train_batch2.jpg\n",
            "runs/detect/train3/train_batch1.jpg\n",
            "runs/detect/train3/args.yaml\n",
            "runs/detect/train3/train_batch68761.jpg\n",
            "runs/detect/train3/results.csv\n",
            "runs/detect/train3/train_batch68762.jpg\n",
            "runs/detect/train3/labels.jpg\n",
            "runs/detect/train/\n",
            "runs/detect/train/weights/\n",
            "runs/detect/train/args.yaml\n",
            "runs/detect/val/\n",
            "runs/detect/val/val_batch1_labels.jpg\n",
            "runs/detect/val/BoxF1_curve.png\n",
            "runs/detect/val/val_batch1_pred.jpg\n",
            "runs/detect/val/val_batch2_pred.jpg\n",
            "runs/detect/val/confusion_matrix.png\n",
            "runs/detect/val/val_batch2_labels.jpg\n",
            "runs/detect/val/BoxP_curve.png\n",
            "runs/detect/val/val_batch0_labels.jpg\n",
            "runs/detect/val/confusion_matrix_normalized.png\n",
            "runs/detect/val/BoxR_curve.png\n",
            "runs/detect/val/BoxPR_curve.png\n",
            "runs/detect/val/val_batch0_pred.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download and extract files from /content/drive/MyDrive/driving-video-with-object-tracking/runs.tar.gz\n",
        "!cp /content/drive/MyDrive/driving-video-with-object-tracking/runs.tar.gz /tmp/\n",
        "!tar -xzvf /tmp/runs.tar.gz -C /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dAtinF7GrVuB",
        "outputId": "23df439f-1b3f-4ada-97a3-ba3656106713"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "runs/\n",
            "runs/detect/\n",
            "runs/detect/train2/\n",
            "runs/detect/train2/args.yaml\n",
            "runs/detect/train2/train_batch1.jpg\n",
            "runs/detect/train2/labels_correlogram.jpg\n",
            "runs/detect/train2/train_batch2.jpg\n",
            "runs/detect/train2/labels.jpg\n",
            "runs/detect/train2/results.csv\n",
            "runs/detect/train2/weights/\n",
            "runs/detect/train2/weights/best.pt\n",
            "runs/detect/train2/weights/last.pt\n",
            "runs/detect/train2/train_batch0.jpg\n",
            "runs/detect/train3/\n",
            "runs/detect/train3/args.yaml\n",
            "runs/detect/train3/train_batch1.jpg\n",
            "runs/detect/train3/labels_correlogram.jpg\n",
            "runs/detect/train3/train_batch2.jpg\n",
            "runs/detect/train3/labels.jpg\n",
            "runs/detect/train3/train_batch68761.jpg\n",
            "runs/detect/train3/train_batch68762.jpg\n",
            "runs/detect/train3/results.csv\n",
            "runs/detect/train3/weights/\n",
            "runs/detect/train3/weights/best.pt\n",
            "runs/detect/train3/weights/last.pt\n",
            "runs/detect/train3/train_batch68760.jpg\n",
            "runs/detect/train3/train_batch0.jpg\n",
            "runs/detect/train/\n",
            "runs/detect/train/args.yaml\n",
            "runs/detect/train/weights/\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b79589a77934f989cb05be670255821": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bc838a0d54743ada3d355af46b87509",
            "placeholder": "​",
            "style": "IPY_MODEL_3d47999e9ba6434f8ddcca0cc090d205",
            "value": "Downloading readme: "
          }
        },
        "11177c3ef850464a80396b66d26c365a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bc2d13f93d74f9fac7422e3b9081470": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d47999e9ba6434f8ddcca0cc090d205": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "475234f867b64a7f96b8a0664673d394": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b0f7d56e68c421f9e1154eb80eccf92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b79589a77934f989cb05be670255821",
              "IPY_MODEL_ac05d72a255e49a6851f58b35c18731a",
              "IPY_MODEL_ea824a0c571d48c59094e9b3c0d2b4cb"
            ],
            "layout": "IPY_MODEL_da90b19b7bee455f8eac0adb3ed72e7e"
          }
        },
        "6bc838a0d54743ada3d355af46b87509": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f405781a1c44f2298190be6eb73c073": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ac05d72a255e49a6851f58b35c18731a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f405781a1c44f2298190be6eb73c073",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11177c3ef850464a80396b66d26c365a",
            "value": 1
          }
        },
        "da90b19b7bee455f8eac0adb3ed72e7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea824a0c571d48c59094e9b3c0d2b4cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bc2d13f93d74f9fac7422e3b9081470",
            "placeholder": "​",
            "style": "IPY_MODEL_475234f867b64a7f96b8a0664673d394",
            "value": " 5.38k/? [00:00&lt;00:00, 315kB/s]"
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}